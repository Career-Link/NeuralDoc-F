{
    "Conclusion": {
        "cnn1": [
            {
                "text": "Convolutional Neural Networks differ to other forms of Artifical Neural Network in that instead of focusing on the entirety of the problem domain, knowledge about the specific type of input is exploited. This in turn allows for a much simpler network architecture to be set up.\n\nThis paper has outlined the basic concepts of Convolutional Neural Networks, explaining the layers required to build one and detailing how best to structure the network in most image analysis tasks.\n\nResearch in the field of image analysis using neural networks has somewhat slowed in recent times. This is partly due to the incorrect belief surrounding the level of complexity and knowledge required to begin modelling these superbly powerful machine learning algorithms. The authors hope that this paper has in some way reduced this confusion, and made the field more accessible to beginners.",
                "similarity": 0.9333658218383789
            }
        ],
        "cnn3": [
            {
                "text": "CNNs are considered the gold standard in deep learning-based image analysis. For instance, in biomedical imaging, they overcome the drawbacks of subjective analysis in the semi-quantitative visual inspection of samples (Gurcan et al., 2009), and they support experts\n\n\nFigure 6: Class activation maps (CAMs) of a FF trained CNN show which image regions are considered beneficial (yellow) or deleterious (pink) by the network for making its prediction. (A), (C), (E), and (G) display four input images. (B), (D), (F), and (H) are their corresponding CAMs. All examples are from a network with 16 convolutional neurons per layer, filter size 5x5, and trained with a batch size of 50.\n\n| A | B | C | D |\n|---|---|---|---|\n| 1 | Heatmap | 2 | Heatmap |\n| E | F | G | H |\n| 7 | Heatmap | 9 | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nFigure 7: Class activation maps show that the different layers of the FF-trained CNN provide similar, but yet distinguishable information. (A) shows the CAM obtained from considering both layer 2 and layer 3 together. (B) and (C) show the CAMs obtained respectively only from layer 2 and layer 3.\n\n| A | B | C |\n|---|---|---|\n| Heatmap | Heatmap | Heatmap |\n\nColor scale: -0.04 (purple) to 0.04 (yellow)\n\nduring their daily clinical routine by reducing their workload (Shmatko et al., 2022). Furthermore, their exploitation of the spatial information within images makes them suitable for the deployment of explainable AI tools (such as class activation maps), which highlight the image regions contributing most significantly to the classification outcome. Our implementation of FF trained CNN shows that with the right choice of hyperparameters, this technique is competitive with backpropagation. These results were obtained without implementing all the possible and suggested optimizations such as enforcing symmetry of the loss function (Lee and Song, 2023) or choosing hard, i.e. easily confused, labels for the negative data set, as suggested by Hinton (2022). We propose that our work shows the\n\nSCODELLARO, KULKARNI, ALVES AND SCHR\u00d6TER\n\npotential of FF trained CNNs to address real world computer vision problems. An open question remains if this technique will supersede BP in specific applications. We believe that this potential exists, especially in the cases of neuromorphic hardware and unsupervised learning.\n\nA better understanding of the FF training will however also expand our understanding of the generic concept of neuronal information processing in all its breadth from biological systems to reservoir computing. The demonstrated capability to implement class activation maps offers an initial insight into these research topics. Achieving deeper insights will also mean to understand how the two innovations of FF, providing positive and negative labels and computing a locally defined goodness parameter, contribute to its success individually and synergetically (Tosato et al., 2023). Moreover, a better understanding why it is beneficial to exclude the first layer during the goodness computation (c.f. Appendix B) would be desirable. Subsequent work on FF training should also address its ability to train deeper networks, most likely expanding on the work of Lorberbom et al. (2023). Also the ability of FF training to work with larger and more complex data sets needs to be explored. Finally, its connection to biological neuronal systems (Ororbia and Mali, 2023; Ororbia, 2023) seems a promising research direction.",
                "similarity": 0.8813095092773438
            }
        ],
        "cnn5": [
            {
                "text": "We propose an enhanced CNN architecture tailored specifically for image classification tasks on the CIFAR-10 dataset. This architecture leverages deeper convolutional layers, which enable the model to learn more complex and hierarchical features from the input images. The inclusion of batch normalization plays a critical role in stabilizing the training process by normalizing intermediate feature distributions, thereby mitigating the issue of vanishing or exploding gradients. Dropout layers are strategically integrated into the architecture to address overfitting, ensuring that the model generalizes well to unseen data. These combined enhancements contribute to the model achieving a test accuracy of 84.95%, which represents a significant improvement over standard baseline CNN models.\n\nThe improvements observed with the proposed architecture underscore the importance of refining network design to balance depth, feature extraction capabilities, and regularization techniques. By carefully combining these elements, the model not only improves classification accuracy but also exhibits better robustness and generalization across the diverse image categories within CIFAR-10. These results highlight the potential of enhanced CNNs for tackling image classification tasks that require extracting fine-grained visual features while maintaining computational efficiency.\n\nFuture work will focus on extending this enhanced architecture to more complex datasets such as CIFAR-100, which consists of 100 classes and provides a more challenging testbed for multi-class classification models. Additionally, transfer learning techniques will be explored to adapt the proposed architecture to larger datasets with higher-resolution images, such as ImageNet, or domain-specific datasets, where pre-trained models can be fine-tuned for specialized tasks. These extensions will allow for further evaluation of the architecture's scalability and applicability across a broader range of computer vision problems, paving the way for its integration into practical applications.",
                "similarity": 0.9361571669578552
            }
        ],
        "pdf2": [
            {
                "text": "Recent years have witnessed the advent of deep learning methods for structural biology culminating in the award of the Nobel Prize in Chemistry. AlphaFold (Jumper et al., 2021) revolutionized protein structure prediction, equipping the field with millions of new structures. Breakthroughs go beyond structure prediction, notably in protein design (Watson et al., 2023; Dauparas et al., 2022), drug discovery (Schneuing et al., 2024; Corso et al., 2022) or fundamental biology (van Kempen et al., 2022). While it is tempting to attribute the success of these methods to the increase in available structural data caused by AlphaFold, most of the methods are actually not reliant on them. Instead, it seems that these breakthroughs result from progress in training neural encoders that directly model protein structures (Jing et al., 2020; Zhang et al., 2022b; Gainza et al., 2020; Wang et al., 2022). This progress is in turn rooted in solid competitions (CASP, CAPRI), and benchmarks (Townshend et al., 2021a; Kucera et al., 2023; Zhu et al., 2022; Jamasb et al., 2024; Notin et al., 2023). By setting clear goals, such benchmarks are the foundation for the development of structure encoders. Yet to date, structure-function benchmarks have focused on proteins.\n\nRibonucleic acids (RNAs) are a large family of molecules which support biological functions along every branch of the tree of life. Besides messenger RNAs, non-coding RNAs carry out biological functions by adopting complex 3D folds (Cech & Steitz, 2014) like proteins do and take up diverse roles in cellular functions, including gene regulation, RNA processing, and protein synthesis (Statello et al., 2021). However, our understanding of non-coding RNAs and their functions remains limited. This can be largely attributed to the negatively charged nature of RNA backbones, which makes it flexible and limits the availability of high-resolution RNA structures, and imposes significant modeling challenges. Another predominant challenge to a functional understanding of RNA 3D structure lies in the lack of infrastructure for the development and evaluation of function prediction models. In this work, we propose a benchmarking suite to act as this facilitating framework.\n\nOur key contributions include:\n\n- Seven tasks related to RNA 3D structure that represent various biological challenges. Each task consists of a dataset, a splitting strategy, and an evaluation method, laying the ground for comparable, reproducible model development.\n\n- End-to-end reproducible and modular access to task data. Modular annotators, filters and splitting strategies, both novel and from existing literature, facilitate the addition of new tasks by other researchers across fields.\n\n*Equal contribution \u2020Equal supervision 1Max Planck Institute of Biochemistry, Munich, Germany 2Mines Paris, PSL Research University, CBIO, Paris, France 3Vanderbilt University, Nashville, Tennessee, USA. Correspondence to: Luis Wyss <wyss@biochem.mpg.de>.\n\nA preprint.\n\nBenchmark for RNA 3D Structure Modeling",
                "similarity": 0.8349259495735168
            }
        ],
        "pdf4": [
            {
                "text": "Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261\u20132285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52\u201372.\n\nBreymann, W. and L\u00fcthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693\u2013703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 \u2013 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817\u2013823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265\u2013286.\n\nHyv\u00e4rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695\u2013709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980\u20131000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241\u2013255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316\u2013327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein's lemma. Journal of the American Statistical Association 87 1025\u20131039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009\u20131052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163\u2013194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359\u201325369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612\u2013622.\n\nO'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26\u201359.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559\u2013572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144\u2013150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955\u2013963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769\u2013782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661\u20131674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore\u2013penrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein's method. Advances in Neural Information Processing Systems 30 6097\u20136106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis\u2013kahan theorem for statisticians. Biometrika 102 315\u2013323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329\u2013346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n\"Nonlinear Multiple Response Regression and Learning of Latent Spaces\"\n\nYe Tian, Sanyou Wu and Long Feng",
                "similarity": 0.8212827444076538
            }
        ],
        "cnn2": [
            {
                "text": "In this paper, we tried to analyze the properties of convolutional neural networks. A simplified model, the scattering transform was introduced as a first step towards understanding CNN operations. We saw that the feature transformation is built on top of wavelet transforms which separate variations at different scales using a wavelet transform. The analysis of general CNN architectures was not considered in this paper, but even this analysis is only a first step towards a full mathematical understanding of convolutional neural networks.",
                "similarity": 0.9318594932556152
            }
        ],
        "cnn4": [
            {
                "text": "In this article, we introduced the Self Expanding Convolutional Neural Network, a dynamically expanding architecture that uses the natural expansion score to optimize model growth. The CIFAR-10 dataset was used to train an initial model consisting over 5 different trials, which resulted in a 84.1% mean validation accuracy. Our model demonstrates how a Self Expanding CNN offers a computationally efficient solution to dynamically determine an optimal architecture for vision tasks while eliminating the need to restart or train multiple models.",
                "similarity": 0.9318594932556152
            }
        ],
        "pdf1": [
            {
                "text": "This work introduced a cross-correlation-aware deep INS/DVL fusion framework that integrates the strengths of both data-driven and model-based approaches. First, we built upon a previous work called BeamsNet and showed its robustness to unseen data. Then, by incorporating deep learning-based velocity estimates into an error-state EKF with an explicit cross-covariance model, we achieved a solution that is not only superior in terms of accuracy when compared to the model-based least squares approach but also more consistent and theoretically grounded. The proposed method addresses a critical limitation of traditional EKF formulations, namely the assumption of uncorrelated process and measurement noise, a condition often violated when using data-driven measurements. Our results demonstrate that accounting for these correlations yields improved confidence in state estimates and reduced uncertainty over time.\n\nBeyond its empirical advantages, this approach offers a principled pathway for integrating modern deep learning techniques within the well-established Kalman filtering framework. This synergy is especially crucial in real-time underwater navigation applications, where reliability, robustness, and theoretical soundness are essential for operational success.",
                "similarity": 0.9193439483642578
            }
        ],
        "pdf3": [
            {
                "text": "",
                "similarity": 0.8355896472930908
            }
        ]
    }
}