    
            I am providing a JSON containing text excerpts that match a user's query with a similarity score of 0.85 or higher. Your task is to generate concise, well-structured, and contextually relevant headdings and summaries based on this content.

            Instructions:
            - Heading should be from "sub-headding" key value of the given json and remove any Initial number given before the headding text.
            - Multiple "sub-headding" could have same heading so provide multiple heading and summries but they should not be same.
            - The headding and summaries should be clear, concise, and directly relevant to the userâ€™s query.
            - Retain the most important insights while eliminating redundancy.
            - Ensure the summary is logically structured and coherent.
            - If multiple texts provide different perspectives, synthesize them into a unified and meaningful response.
            - Avoid unnecessary details, focusing only on highly relevant information.
            Input:
                [
    {
        "text": "[1] J. Nicholson and A. Healey, \"The present state of autonomous underwater vehicle (AUV) applications and technologies,\" Marine Technology Society Journal, vol. 42, no. 1, pp. 44\u201351, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, \"Autonomous underwater vehicle navigation,\" IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663\u2013678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, \"Doppler Velocity Log theory and preliminary considerations for design and construction,\" in 2012 Proceedings of IEEE Southeastcon, pp. 1\u20137, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, \"Inertial navigation meets deep learning: A survey of current trends and future directions,\" Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, \"Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation,\" Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, \"Sins/dvl integrated navigation method with current compensation using rbf neural network,\" IEEE Sensors Journal, vol. 22, no. 14, pp. 14366\u201314377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, \"An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments,\" Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, \"Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment,\" in OCEANS 2024-Singapore, pp. 1\u20136, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, \"DCNet: A data-driven framework for DVL calibration,\" Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, \"MissBeamNet: Learning missing Doppler velocity log beam measurements,\" Neural Computing and Applications, vol. 36, no. 9, pp. 4947\u20134958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, \"Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios,\" in 2023 IEEE Underwater Technology (UT), pp. 1\u20136, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, \"BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation,\" Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, \"Adaptive Kalman-Informed Transformer,\" Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, \"Adaptive Neural Unscented Kalman Filter,\" arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, \"AUV Acceleration Prediction Using DVL and Deep Learning ,\" arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.",
        "sub_heading": "REFERENCES",
        "collection_name": "pdf1",
        "similarity": 0.8010231256484985
    },
    {
        "text": "An LSTM network (Hochreiter and Schmidhuber, 1997) is a type of recurrent neural network, which incorporates both short and long-term effects based on data-adaptive learning for estimation of a system, function, or process. The architecture of an LSTM cell including the inputs, outputs, and short and long-term memory components is in Figure 3.\n\n![Figure 3: Basic architecture of an LSTM cell]\n\nInside the cell, the circled functions labeled (f\u2081, f\u2082, f\u2083, f\u2084) are representative of an LSTM unit, and circled operators are component-based operations. Sigma (\u03c3) is the sigmoid activation function, and tanh is the hyperbolic tangent activation. The size of the weight and bias matrices in the LSTM unit defines the size or dimensionality of the hidden and cell states.\n\nWeights are represented by (W,U), biases (b), and Hadamard product (\u25cb). Based on the training of the neural network, each of the weights and biases are \"learned\" through an optimization process. The hidden state (h\u209c) and cell state (c\u209c) act as \"memory\", and change over time.\n\nThe following equations show the compact form of the operations inside of the cell.\n\n$$f_1 = \u03c3(W_{f1} \\cdot x^{(t)} + U_{f1} \\cdot h^{(t-1)} + b_{f1})$$\n\n$$f_2 = \u03c3(W_{f2} \\cdot x^{(t)} + U_{f2} \\cdot h^{(t-1)} + b_{f2})$$\n\n$$f_3 = tanh(W_{f3} \\cdot x^{(t)} + U_{f3} \\cdot h^{(t-1)} + b_{f3})$$\n\n$$f_4 = \u03c3(W_{f4} \\cdot x^{(t)} + U_{f4} \\cdot h^{(t-1)} + b_{f4})$$\n\n$$c_t = f_1 \\circ c^{(t-1)} + f_2 \\circ f_3$$\n\n$$h_t = f_4 \\circ tanh(c^{(t)})$$\n\nFunction (\ud835\udc531) is the \"forget gate\", which controls the parts of the long-term state that are deleted. Function (\ud835\udc533) represents the input gate, which controls the information from (\ud835\udc532) that is added to the long-term state. Function (\ud835\udc534) controls the output gate, which determines the output of the long-term state.\n\nBy constructing layers of cells, the LSTM network is capable of forecasting a desired response to a provided input. An LSTM network effectively maps the input time-series to the desired output time-series or target(s). Adding more units to each cell or increasing the number of layers can enable the network to model more complex interactions or behaviors, but at greater computational cost.\n\nThe training process as well as the accuracy and deficiency of an LSTM network depend on the selection of hyperparameters. The accuracy and time-efficiency of an LSTM network depend on the hyperparameters. The hyperparameters are comprised of the number of inputs, number of network layers, training data sequence length, time resolution of the input time-series, hidden state size, bi-directionality, and dropout method. The length of the training data sequences is equivalent to the number of samples of the input time-series.\n\nTime resolution is based on uniform resampling of the input and target time-series. Through resampling, each time-series is reconfigured into a matrix of size [N/\u03c4, \u03c4]; where, N is the original time-series length, and \u03c4 is the time resolution factor. If N is not divisible by \u03c4, then the time-series is reduced in length to the closest multiple of \u03c4.\n\nThe network includes layers of LSTM cells that contain the hidden states. The hidden state size is the number of parameters (\u210e\ud835\udc61), which affects the number of weights in an LSTM unit. Size of the weights vectors are W \u2208 R^hxd and U \u2208 R^hxd for hidden state size (h), and number of input time-series channels (d).\n\nThe basic architecture of the LSTM framework in this study is in Figure 4.\n\n```\n1st LSTM   2nd LSTM   3rd LSTM   Output\nlayer      layer      layer      layer\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 f1  \u2502    \u2502 f1  \u2502    \u2502 f1  \u2502    \u2502O3 \u2502    \u2502 \u03b73,1^LAMP \u03b71,1^LAMP \u03b75,1^LAMP \u2502\n\u2502     \u2502    \u2502     \u2502    \u2502     \u2502    \u2502   \u2502    \u2502                 \u2502\n\u2502 f2  \u2502 -> \u2502 f2  \u2502 -> \u2502 f2  \u2502 -> \u2502O4 \u2502 -> \u2502 \u03b73,2^LAMP \u03b71,2^LAMP \u03b75,2^LAMP \u2502\n\u2502     \u2502    \u2502     \u2502    \u2502     \u2502    \u2502   \u2502    \u2502     ...         \u2502\n\u2502 f3  \u2502    \u2502 f3  \u2502    \u2502 f3  \u2502    \u2502O5 \u2502    \u2502 \u03b73,4^LAMP \u03b71,4^LAMP \u03b75,4^LAMP \u2502\n\u2502     \u2502    \u2502     \u2502    \u2502     \u2502    \u2502   \u2502    \u2502                 \u2502\n\u2502 f4  \u2502    \u2502 f4  \u2502    \u2502 f4  \u2502    \u2514\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\u2514\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2518    \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n```\n\nFigure 4: LSTM Architecture\n\nAn additional fully connected linear output layer has been inserted after the three LSTM layers to parse the output into individual time-series channels for the 3-DOF motions for roll, pitch and heave. Also the labels \"SC\" and \"LAMP\" indicate the source of the time-series values. Definitions of the parameters are in Table 1.\n\n| Parameter Definition | Variable |\n|----------------------|----------|\n| Input wave at time-step j | \u03b7_o,j |\n| Total number time steps | T |\n| i^th degree-of-freedom at time-step j | \u03b7_i,j |\n| k^th gate for LSTM layer | f_k |\n| Number of LSTM units per layer | n |\n| Output layer cell for DOF m | O_m |\n\nTable 1: Parameters for LSTM Architecture\n\nThe LSTM framework is comprised of two-stages with SimpleCode as the first stage and LSTM network as the second. In this architecture, four time-series channels are applied as inputs to the LSTM network.\n\nThe input channels encompass the 3-DOF motion responses from SimpleCode, and corresponding input wave time-series data. The output response time-series from the two-stage LSTM-SimpleCode model are then compared to 3-DOF motion time-series target from LAMP. The result of training is a set of weights and biases that can be insert directly into Equations 1-6 or into LSTM configurations in existing machine learning packages such as PyTorch in python.\n\npoints per realization (N), and time resolution factor (\u03c4). Each LSTM layer consisted of a single LSTM cell with its own set of gates (f\u2081, f\u2082, f\u2083, f\u2084), distinct weights, and biases.\n\nThe training values for the hyperparameters are in Table 3.\n\nTable 3: Training Values for Hyperparameters\n\n| Hyperparameter | Value |\n|----------------|-------|\n| Time Resolution Factor | 9 |\n| Hidden State Size | 30 |\n| Number of LSTM Layers | 2 |\n| Learning Rate | 0.01 |",
        "sub_heading": "2.1 Long Short-Term Memory",
        "collection_name": "pdf3",
        "similarity": 0.8147710561752319
    },
    {
        "text": "Convolutional Neural Networks (CNNs), introduced by Le Cun et al. [6] are a class of biologically inspired neural networks which solve equation (1) by passing X through a series of convolutional filters and simple non-linearities. They have shown remarkable results in a wide variety of machine learning problems [8]. Figure 1 shows a typical CNN architecture.\n\nA convolutional neural network has a hierarchical architecture. Starting from the input signal x, each subsequent layer xj is computed as\n\n$$x_j = \\rho W_j x_{j-1} \\tag{5}$$\n\nHere Wj is a linear operator and \u03c1 is a non-linearity. Typically, in a CNN, Wj is a convolution, and \u03c1 is a rectifier max(x, 0) or sigmoid 1/1+exp(\u2212x). It is easier to think of the operator Wj as a stack of convolutional filters. So the layers are filter maps and each layer can be written as a sum of convolutions of the previous layer.\n\n$$x_j(u, k_j) = \\rho \\left( \\sum_k (x_{j-1}(., k) * W_{j,k_j}(., k))(u) \\right) \\tag{6}$$\n\nHere * is the discrete convolution operator:\n\n$$(f * g)(x) = \\sum_{u=-\\infty}^{\\infty} f(u)g(x - u) \\tag{7}$$\n\nThe optimization problem defined by a convolutional neural network is highly non-convex. So typically, the weights Wj are learned by stochastic gradient descent, using the backpropagation algorithm to compute gradients.\n\nFigure 1: Architecture of a Convolutional Neural Network (from LeCun et al. [7])\n\n| Layer | Description | Size/Maps |\n|-------|-------------|-----------|\n| INPUT | Input layer | 32x32 |\n| C1 | Feature maps | 6@28x28 |\n| S2 | Subsampling | 6@14x14 |\n| C3 | Feature maps | 16@10x10 |\n| S4 | Subsampling | 16@5x5 |\n| C5 | Fully connected layer | 120 |\n| F6 | Fully connected layer | 84 |\n| OUTPUT | Output layer | 10 |\n\nConvolutions -> Subsampling -> Convolutions -> Subsampling -> Full connection -> Gaussian connections",
        "sub_heading": "1.5 Convolutional Neural Networks",
        "collection_name": "cnn2",
        "similarity": 0.8557035326957703
    },
    {
        "text": "Mallat [10] introduced a mathematical framework for analyzing the properties of convolutional networks. The theory is based on extensive prior work on wavelet scattering (see for example [2, 1]) and illustrates that to compute invariants, we must separate variations of X at different scales with a wavelet transform. The theory is a first step towards understanding general classes of CNNs, and this paper presents its key concepts.",
        "sub_heading": "1.6 A mathematical framework for CNNs",
        "collection_name": "cnn2",
        "similarity": 0.8287503719329834
    },
    {
        "text": "The scattering transform described in the previous section provides a simple view of a general convolutional neural netowrk. While it provides intuition behind the working of CNNs, the transformation suffers from high variance and loss of information because we only consider single channel convolutions. To analyze the properties of general CNN architectures, we must allow for channel combinations. Mallat [10] extends previously introduced tools to develop a mathematical framework for this analysis. The theory is, however, out of the scope of this paper. At a high level, the extension is achieved by replacing the requirement of contractions and invariants to translations by contractions along adaptive groups of local symmetries. Further, the wavelets are replaced by adapted filter weights similar to deep learning models.",
        "sub_heading": "5 General Convolutional Neural Network Architectures",
        "collection_name": "cnn2",
        "similarity": 0.8038275241851807
    },
    {
        "text": "To avoid the loss of information that comes from integrating over all time, we might use a weight function that localizes f in time. Without going into specifics, let us consider some function g supported on [\u2212T, 0] and define the windowed Fourier transform (WFT) as\n\n$$\\tilde{f}(\\omega, t) \\equiv \\int_{-\\infty}^{\\infty} f(u)g(u - t)e^{-2\\pi i\\omega u} du$$\n\nIt should be intuitively clear that the WFT can capture local variations in a time window of width T. Further, it can be shown that the WFT also provides accurate information about f in a frequency band\n\n3\n\nof some width \u03a9. So does the WFT solve our problem? Unfortunately not; and this is a consequence of Theorem 1 which is stated very informally next.",
        "sub_heading": "2 The need for wavelets",
        "collection_name": "cnn2",
        "similarity": 0.803309440612793
    },
    {
        "text": "The Fourier transform of f is defined as\n\n$$\\hat{f}(\\omega) \\equiv \\int_{-\\infty}^{\\infty} f(t)e^{-2\\pi i\\omega t} dt$$\n\nThe Fourier transform is a powerful tool which decomposes f into the frequencies that make it up. However, it should be quite clear from equation (8) that it is useless for the task we are interested in. Since the integral is from \u2212\u221e to \u221e, $\\hat{f}$ is an average over all time and does not have any local information.",
        "sub_heading": "2 The need for wavelets",
        "collection_name": "cnn2",
        "similarity": 0.803309440612793
    },
    {
        "text": "machine learning, self expanding neural networks, computational efficiency, convolutional neural networks.",
        "sub_heading": "Keywords",
        "collection_name": "cnn4",
        "similarity": 0.8004220724105835
    },
    {
        "text": "1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. \"72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data.\" SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. \"Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network.\" 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. \"Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling.\" arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veli\u010dkovi\u0107, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. \"Inductive representation learning on large graphs.\" Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. \"Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis.\" Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. \"Parameterized maximum-entropy-based three-way approximate attribute reduction.\" International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. \"FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders.\" arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, \"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),\" PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. \"Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning.\" arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, \"End-to-End Text-Dependent Speaker Verification,\" in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115\u20135119.\n\n13. S. Hochreiter and J. Schmidhuber, \"Long Short-Term Memory,\" Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, \"Learning to Forget: Continual Prediction with LSTM,\" Neural Computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. \"Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective.\" arXiv preprint arXiv:2411.14654 (2024).",
        "sub_heading": "REFERENCES",
        "collection_name": "cnn5",
        "similarity": 0.8010231256484985
    },
    {
        "text": "Abulwerdi, F. A., Xu, W., Ageeli, A. A., Yonkunas, M. J., Arun, G., Nam, H., Schneekloth Jr, J. S., Dayie, T. K., Spector, D., Baird, N., et al. Selective small-molecule targeting of a triple helix encoded by the long noncoding rna, malat1. ACS chemical biology, 14(2):223\u2013235, 2019.\n\nAdamczyk, B., Antczak, M., and Szachniuk, M. Rnasolo: a repository of cleaned pdb-derived rna 3d structures. Bioinformatics, 38(14):3668\u20133670, 2022.\n\nAlam, T., Uludag, M., Essack, M., Salhi, A., Ashoor, H., Hanks, J. B., Kapfer, C., Mineta, K., Gojobori, T., and Bajic, V. B. Farna: knowledgebase of inferred functions of non-coding rna transcripts. Nucleic acids research, 45 (5):2838\u20132848, 2017.\n\nAnand, R., Joshi, C. K., Morehead, A., Jamasb, A. R., Harris, C., Mathis, S. V., Didi, K., Hooi, B., and Lio, P. Rnaframeflow: Flow matching for de novo 3d rna backbone design. arXiv preprint arXiv:2406.13839, 2024.\n\nAshburner, M., Ball, C. A., Blake, J. A., Botstein, D., Butler, H., Cherry, J. M., Davis, A. P., Dolinski, K., Dwight, S. S., Eppig, J. T., et al. Gene ontology: tool for the unification of biology. Nature genetics, 25(1):25\u201329, 2000.\n\nBecquey, L., Angel, E., and Tahi, F. Rnanet: an automatically built dual-source dataset integrating homologous sequences and rna structures. Bioinformatics, 37(9):1218\u20131224, 2021.\n\nBoccaletto, P., Stefaniak, F., Ray, A., Cappannini, A., Mukherjee, S., Purta, E., Kurkowska, M., Shirvanizadeh, N., Destefanis, E., Groza, P., et al. Modomics: a database of rna modification pathways. 2021 update. Nucleic acids research, 50(D1):D231\u2013D235, 2022.\n\nButtenschoen, M., Morris, G. M., and Deane, C. M. Posebusters: Ai-based docking methods fail to generate physically valid poses or generalise to novel sequences. Chemical Science, 15(9):3130\u20133139, 2024.\n\nCarvajal-Patino, J. G., Mallet, V., Becerra, D., Ni\u00f1o Vasquez, L. F., Oliver, C., and Waldisp\u00fchl, J. Rnamigos2: accelerated structure-based rna virtual screening with deep graph learning. Nature Communications, 16(1):1\u201312, 2025.\n\nCech, T. R. and Steitz, J. A. The noncoding rna revolution\u2014trashing old rules to forge new ones. Cell, 157(1): 77\u201394, 2014.\n\nCorso, G., St\u00e4rk, H., Jing, B., Barzilay, R., and Jaakkola, T. Diffdock: Diffusion steps, twists, and turns for molecular docking. arXiv preprint arXiv:2210.01776, 2022.\n\nDauparas, J., Anishchenko, I., Bennett, N., Bai, H., Ragotte, R. J., Milles, L. F., Wicky, B. I., Courbet, A., de Haas, R. J., Bethel, N., et al. Robust deep learning\u2013based protein sequence design using proteinmpnn. Science, 378 (6615):49\u201356, 2022.\n\nDisney, M. D. Targeting rna with small molecules to capture opportunities at the intersection of chemistry, biology, and medicine. Journal of the American Chemical Society, 141 (17):6776\u20136790, 2019.\n\nDurairaj, J., Adeshina, Y., Cao, Z., Zhang, X., Oleinikovas, V., Duignan, T., McClure, Z., Robin, X., Kovtun, D., Rossi, E., et al. Plinder: The protein-ligand interactions dataset and evaluation resource. bioRxiv, pp. 2024\u201307, 2024.\n\nFalese, J. P., Donlic, A., and Hargrove, A. E. Targeting rna with small molecules: from fundamental principles towards the clinic. Chemical Society Reviews, 50(4): 2224\u20132243, 2021.\n\nFu, L., Niu, B., Zhu, Z., Wu, S., and Li, W. Cd-hit: accelerated for clustering the next-generation sequencing data. Bioinformatics, 28(23):3150\u20133152, 2012.\n\nGainza, P., Sverrisson, F., Monti, F., Rodol\u00e0, E., Boscaini, D., Bronstein, M., and Correia, B. Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning. Nature Methods, 17(2):184\u2013192, 2020.\n\nGligorijevic, V., Renfrew, P. D., Kosciolek, T., Leman, J. K., Berenberg, D., Vatanen, T., Chandler, C., Taylor, B. C., Fisk, I. M., Vlamakis, H., et al. Structure-based protein function prediction using graph convolutional networks. Nature communications, 12(1):3168, 2021.\n\nGlisovic, T., Bachorik, J. L., Yong, J., and Dreyfuss, G. Rna-binding proteins and post-transcriptional gene regulation. FEBS letters, 582(14):1977\u20131986, 2008.\n\nGriffiths-Jones, S., Bateman, A., Marshall, M., Khanna, A., and Eddy, S. R. Rfam: an rna family database. Nucleic acids research, 31(1):439\u2013441, 2003.\n\nHaga, C. L. and Phinney, D. G. Strategies for targeting rna with small molecule drugs. Expert Opinion on Drug Discovery, 18(2):135\u2013147, 2023.\n\nHou, J., Adhikari, B., and Cheng, J. Deepsf: deep convolutional neural network for mapping protein sequences to folds. Bioinformatics, 34(8):1295\u20131303, 2018.\n\nBenchmark for RNA 3D Structure Modeling\n\nHuang, H., Lin, Z., He, D., Hong, L., and Li, Y. Ribodiffusion: tertiary structure-based rna inverse folding with generative diffusion models. Bioinformatics, 40 (Supplement 1):i347\u2013i356, 2024.\n\nJamasb, A. R., Morehead, A., Joshi, C. K., Zhang, Z., Didi, K., Mathis, S., Harris, C., Tang, J., Cheng, J., Lio, P., et al. Evaluating representation learning on the protein structure universe. ArXiv, pp. arXiv\u20132406, 2024.\n\nJing, B., Eismann, S., Suriana, P., Townshend, R. J., and Dror, R. Learning from protein structure with geometric vector perceptrons. arXiv preprint arXiv:2009.01411, 2020.\n\nJing, B., Eismann, S., Soni, P. N., and Dror, R. O. Equivariant graph neural networks for 3d macromolecular structure, 2021. URL https://arxiv.org/abs/2106.03843.\n\nJoshi, C. K., Jamasb, A. R., Vi\u00f1as, R., Harris, C., Mathis, S. V., Morehead, A., and Lio, P. grnade: Geometric deep learning for 3d rna inverse design. bioRxiv, pp. 2024\u201303, 2024.\n\nJumper, J., Evans, R., Pritzel, A., Green, T., Figurnov, M., Ronneberger, O., Tunyasuvunakool, K., Bates, R., \u017d\u00eddek, A., Potapenko, A., et al. Highly accurate protein structure prediction with alphafold. Nature, 596(7873):583\u2013589, 2021.\n\nKouranov, A., Xie, L., de la Cruz, J., Chen, L., Westbrook, J., Bourne, P. E., and Berman, H. M. The rcsb pdb information portal for structural genomics. Nucleic acids research, 34(suppl 1):D302\u2013D305, 2006.\n\nKovtun, D., Akdel, M., Goncearenco, A., Zhou, G., Holt, G., Baugher, D., Lin, D., Adeshina, Y., Castiglione, T., Wang, X., et al. Pinder: The protein interaction dataset and evaluation resource. bioRxiv, pp. 2024\u201307, 2024.\n\nKucera, T., Oliver, C., Chen, D., and Borgwardt, K. Proteinshake: Building datasets and benchmarks for deep learning on protein structures. In Advances in Neural Information Processing Systems, volume 36, pp. 58277\u201358289, 2023.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665\u2013680, 2020a.\n\nLeman, J. K., Weitzner, B. D., Lewis, S. M., Adolf-Bryfogle, J., Alam, N., Alford, R. F., Aprahamian, M., Baker, D., Barlow, K. A., Barth, P., et al. Macromolecular modeling and design in rosetta: recent methods and frameworks. Nature methods, 17(7):665\u2013680, 2020b.\n\nLeontis, N. B. and Zirbel, C. L. Nonredundant 3d structure datasets for rna knowledge extraction and benchmarking. RNA 3D structure analysis and prediction, pp. 281\u2013298, 2012.\n\nLorenz, R., Bernhart, S. H., H\u00f6ner zu Siederdissen, C., Tafer, H., Flamm, C., Stadler, P. F., and Hofacker, I. L. Viennarna package 2.0. Algorithms for molecular biology, 6:1\u201314, 2011.\n\nMitchell, S., OSullivan, M., and Dunning, I. Pulp: a linear programming toolkit for python. The University of Auckland, Auckland, New Zealand, 65:25, 2011.\n\nNori, D. and Jin, W. Rnaflow: Rna structure and sequence design via inverse folding-based flow matching, 2024. URL https://arxiv.org/abs/2405.18768.\n\nNotin, P., Kollasch, A., Ritter, D., van Niekerk, L., Paul, S., Spinner, H., Rollins, N., Shaw, A., Orenbuch, R., Weitzman, R., Frazer, J., Dias, M., Franceschi, D., Gal, Y., and Marks, D. Proteingym: Large-scale benchmarks for protein fitness prediction and design. In Advances in Neural Information Processing Systems, volume 36, pp. 64331\u201364379, 2023.\n\nOliver, C., Mallet, V., Gendron, R. S., Reinharz, V., Hamilton, W. L., Moitessier, N., and Waldisp\u00fchl, J. Augmented base pairing networks encode rna-small molecule binding preferences. Nucleic acids research, 48(14):7690\u20137699, 2020.\n\nOntiveros-Palacios, N., Cooke, E., Nawrocki, E. P., Triebel, S., Marz, M., Rivas, E., Griffiths-Jones, S., Petrov, A. I., Bateman, A., and Sweeney, B. Rfam 15: Rna families database in 2025. Nucleic Acids Research, 53(D1):D258\u2013D267, 2025.\n\nPanei, F. P., Torchet, R., Menager, H., Gkeka, P., and Bonomi, M. Hariboss: a curated database of rna-small molecules structures to aid rational drug design. Bioinformatics, 38(17):4185\u20134193, 2022.\n\nRen, Y., Chen, Z., Qiao, L., Jing, H., Cai, Y., Xu, S., Ye, P., Ma, X., Sun, S., Yan, H., et al. Beacon: Benchmark for comprehensive rna tasks and language models. Advances in Neural Information Processing Systems, 37:92891\u201392921, 2024.\n\nRoundtree, I. A., Evans, M. E., Pan, T., and He, C. Dynamic rna modifications in gene expression regulation. Cell, 169(7):1187\u20131200, 2017.\n\nRuiz-Carmona, S., Alvarez-Garcia, D., Foloppe, N., Garmendia-Doval, A. B., Juhos, S., Schmidtke, P., Barril, X., Hubbard, R. E., and Morley, S. D. rdock: A\n\nBenchmark for RNA 3D Structure Modeling\n\nfast, versatile and open source program for docking ligands to proteins and nucleic acids. PLoS Computational Biology, 10:1\u20138, 2014. ISSN 15537358. doi: 10.1371/journal.pcbi.1003571.\n\nSchneuing, A., Harris, C., Du, Y., Didi, K., Jamasb, A., Igashov, I., Du, W., Gomes, C., Blundell, T. L., Lio, P., et al. Structure-based drug design with equivariant diffusion models. Nature Computational Science, 4(12): 899\u2013909, 2024.\n\nStatello, L., Guo, C.-J., Chen, L.-L., and Huarte, M. Gene regulation by long non-coding rnas and its biological functions. Nature reviews Molecular cell biology, 22(2): 96\u2013118, 2021.\n\nSu, H., Peng, Z., and Yang, J. Recognition of small molecule\u2013rna binding sites using rna sequence and structure. Bioinformatics, 37(1):36\u201342, 2021.\n\nSzikszai, M., Magnus, M., Sanghi, S., Kadyan, S., Bouatta, N., and Rivas, E. Rna3db: A structurally-dissimilar dataset split for training and benchmarking deep learning models for rna structure prediction. Journal of Molecular Biology, pp. 168552, 2024. ISSN 0022-2836. doi: https://doi.org/10.1016/j.jmb.2024.168552.\n\nTan, C., Zhang, Y., Gao, Z., Hu, B., Li, S., Liu, Z., and Li, S. Z. Rdesign: hierarchical data-efficient representation learning for tertiary structure-based rna design. arXiv preprint arXiv:2301.10774, 2023.\n\nTan, C., Zhang, Y., Gao, Z., Cao, H., Li, S., Ma, S., Blanchette, M., and Li, S. Z. R3design: deep tertiary structure-based rna sequence design and beyond. Briefings in Bioinformatics, 26(1):bbae682, 2025.\n\nTownshend, R., V\u00f6gele, M., Suriana, P., Derry, A., Powers, A., Laloudakis, Y., Balachandar, S., Jing, B., Anderson, B., Eismann, S., Kondor, R., Altman, R., and Dror, R. Atom3d: Tasks on molecules in three dimensions. In Advances in Neural Information Processing Systems, Datasets and Benchmarks, volume 1, 2021a.\n\nTownshend, R. J., Eismann, S., Watkins, A. M., Rangan, R., Karelina, M., Das, R., and Dror, R. O. Geometric deep learning of rna structure. Science, 373(6558):1047\u20131051, 2021b.\n\nvan Kempen, M., Kim, S. S., Tumescheit, C., Mirdita, M., Gilchrist, C. L., S\u00f6ding, J., and Steinegger, M. Foldseek: fast and accurate protein structure search. Biorxiv, pp. 2022\u201302, 2022.\n\nVolkov, M., Turk, J.-A., Drizard, N., Martin, N., Hoffmann, B., Gaston-Math\u00e9, Y., and Rognan, D. On the frustration to predict binding affinities from protein\u2013ligand structures with deep neural networks. Journal of medicinal chemistry, 65(11):7946\u20137958, 2022.\n\nWang, J., Quan, L., Jin, Z., Wu, H., Ma, X., Wang, X., Xie, J., Pan, D., Chen, T., Wu, T., et al. Multimodrlbp: A deep learning approach for multi-modal rna-small molecule ligand binding sites prediction. IEEE Journal of Biomedical and Health Informatics, 2024.\n\nWang, K., Jian, Y., Wang, H., Zeng, C., and Zhao, Y. Rbind: computational network method to predict rna binding sites. Bioinformatics, 34(18):3131\u20133136, 2018.\n\nWang, K., Zhou, R., Wu, Y., and Li, M. Rlbind: a deep learning method to predict rna\u2013ligand binding sites. Briefings in Bioinformatics, 24(1):bbac486, 2023.\n\nWang, L., Liu, H., Liu, Y., Kurtin, J., and Ji, S. Learning hierarchical protein representations via complete 3d graph networks, 2022. URL https://arxiv.org/abs/2207.12600.\n\nWang, R., Fang, X., Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: methodologies and updates. Journal of medicinal chemistry, 48(12):4111\u20134119, 2005a.\n\nWang, R., ueliang Fang, Lu, Y., Yang, C.-Y., and Wang, S. The pdbbind database: Methodologies and updates. Journal of Medicinal Chemistry, 22, 11 2005b. ISSN 4111\u20134119. doi: 10.1021/jm048957q.\n\nWatson, J. L., Juergens, D., Bennett, N. R., Trippe, B. L., Yim, J., Eisenach, H. E., Ahern, W., Borst, A. J., Ragotte, R. J., Milles, L. F., et al. De novo design of protein structure and function with rfdiffusion. Nature, 620(7976): 1089\u20131100, 2023.\n\nWong, F., He, D., Krishnan, A., Hong, L., Wang, A. Z., Wang, J., Hu, Z., Omori, S., Li, A., Rao, J., et al. Deep generative design of rna aptamers using structural predictions. Nature Computational Science, pp. 1\u201311, 2024.\n\nXu, J., Wu, K.-j., Jia, Q.-j., and Ding, X.-f. Roles of mirna and lncrna in triple-negative breast cancer. Journal of Zhejiang University-science b, 21(9):673\u2013689, 2020.\n\nZeng, P. and Cui, Q. Rsite2: an efficient computational method to predict the functional sites of noncoding rnas. Scientific Reports, 6(1):19016, 2016.\n\nZeng, P., Li, J., Ma, W., and Cui, Q. Rsite: a computational method to identify the functional sites of noncoding rnas. Scientific Reports, 5(1):9179, 2015.\n\nZhang, C., Shine, M., Pyle, A. M., and Zhang, Y. Us-align: universal structure alignments of proteins, nucleic acids, and macromolecular complexes. Nature methods, 19(9): 1109\u20131115, 2022a.\n\nZhang, Z., Xu, M., Jamasb, A., Chenthamarakshan, V., Lozano, A., Das, P., and Tang, J. Protein representation learning by geometric structure pretraining. arXiv preprint arXiv:2203.06125, 2022b.\n\n\nZheng, J., Xie, J., Hong, X., and Liu, S. Rmalign: an\nrna structural alignment tool based on a novel scoring\nfunction rmscore. BMC genomics, 20:1\u201310, 2019.\n\nZhu, Z., Shi, C., Zhang, Z., Liu, S., Xu, M., Yuan, X.,\nZhang, Y., Chen, J., Cai, H., Lu, J., et al. Torchdrug: A\npowerful and flexible machine learning platform for drug\ndiscovery. arXiv preprint arXiv:2202.08320, 2022.",
        "sub_heading": "References",
        "collection_name": "pdf2",
        "similarity": 0.8010231256484985
    },
    {
        "text": "For the neural network, we let $F_\\theta(\\cdot) = O^\\top\\phi\\{A^\\top\\phi(\\cdot)\\}$, where $A \\in \\mathbb{R}^{r\\times h}$, $O \\in \\mathbb{R}^{h\\times q}$, $\\phi(\\cdot)$ is the point-wise ReLU function and we let $h = 32$. We implement neural networks in Pytorch. For neural network estimator of B discussed in Section I.4, we minimize the loss function\n\n$$\\ell(\\theta, B) = \\frac{1}{n} \\sum_{i=1}^n \\|y_i - F_\\theta(B^\\top x_i)\\|_2^2,$$\n\nWe use the batch-training strategy to train the neural networks. We use Adam optimizer with Pytorch default parameters. We choose the batch size to be 0.5% of the sample size and train the neural networks for 200 epochs.",
        "sub_heading": "II.3 Structures and Training Details of Neural Networks",
        "collection_name": "pdf4",
        "similarity": 0.8409820199012756
    },
    {
        "text": "The reduced rank regression addresses the following multiple-response linear regression model:\n\n$$y = C^\u22a4x + \u03b5,$$ (S5)\n\nwhere $C \\in \\mathbb{R}^{p\\times q}$ and $\\text{rank}(C) \\leq r$ for some $r \\leq \\min(p,q)$. Let $X$ denote the data matrix $(x_1,\\ldots,x_n)^\u22a4$ and $Y$ denote the response matrix $(y_1,\\ldots,y_n)^\u22a4$, reduced rank regression estimates the coefficient matrix $C$ by solving the constrained optimization problem: $\\hat{C} = \\text{argmin}_{\\text{rank}(C)\\leq r}\\|Y - XC\\|^2_F$.\n\nUnder low-dimensional setting, i.e., rank($C$) is fixed, it is well known that if $r$ is given, $\\hat{C}$ has the closed form (Mukherjee and Zhu, 2011): $\\hat{C} = \\hat{C}_{\\text{ols}}V_rV_r^\u22a4$. $\\hat{C}_{\\text{ols}}$ is the ordinary least squares estimator, i.e., $\\hat{C}_{\\text{ols}} = \\text{argmin}\\|Y = XC\\|^2_F$. $V_r = \\text{SVD}_{l,r}\\{(X\\hat{C}_{\\text{ols}})^\u22a4\\}$, i.e., the matrix consisting of the first $r$ leading right singular vectors of $X\\hat{C}_{\\text{ols}}$.\n\nNotably, in our model (2.2), if we additionally require that $r < q$, and $f_j(v) = a_j^\u22a4v$ for certain $a_j \\in \\mathbb{R}^r, j \\in [q]$, it reduces to model (S5) with $C = BA$, where $A = (a_1,\\ldots,a_q)$. Therefore, model (S5) is a special case of our model (2.2), and $\\hat{C}$ can be used for estimating $B$. The reduced rank regression estimator of $B$ is defined as $\\hat{B}_R = \\text{SVD}_{l,r}(\\hat{C})$.\n\n**Remark I.1.** Under the assumption that $x \\sim N(0,\\Sigma_N)$, and $\\Sigma_N$ is non-degenerate, by Lemma IV.1, $s(x) = \\Sigma_N^{-1}x$, if we let $\\hat{s}(x) = (1/n)(X^\u22a4X)^{-1}x$, then $\\hat{B} = \\text{SVD}_{l,r}(\\hat{C}_{\\text{ols}})$. The difference between $\\hat{B}_R$ and $\\hat{B}$ lies in the projection matrix $V_rV_r^\u22a4$, which can be seen as the benefit of $\\hat{B}_R$ taking advantage of the extra linear information of link functions in model (S5). Results of simulations in Section 4 demonstrate that performances of $\\hat{B}$ and $\\hat{B}_R$ are almost the same when $x \\sim N(0,\\Sigma_N)$, the difference above is almost negligible.\n\nThe multi-index model has a close relationship with NNs, and many works try to show that NNs can be used to estimate MIM and construct the representation space in the low-dimensional setting (Bauer and Kohler, 2019; Damian et al., 2022; Mousavi-Hosseini et al., 2022). Similarly, for our multi-response extension, the matrix $B$ can also be estimated by NNs. Let $F_\u03b8(\\cdot): \\mathbb{R}^r \\to \\mathbb{R}^q$ be a neural network parametrized by $\u03b8$, the neural network estimator $\\hat{B}_N$ can be obtained by\n\n$$(\\hat{\u03b8}_N, \\hat{B}_N) = \\text{argmin}_{(\u03b8,B)} \\frac{1}{n} \\sum_{i=1}^n \\|y_i - F_\u03b8(B^\u22a4x_i)\\|_2^2.$$ (S6)\n\nWe solve the optimization problem by mini-batch gradient descent. For details of the neural network structure and training procedures, please see Section II.3 of the Supplement.\n\nTo apply our method, by densities of $x$, first-order and second-order score functions can be derived in closed forms. Please refer to Section II.4 of Supplement for details. Then, for $x \\sim N(0,\\Sigma_N)$, parameters are estimated by maximum likelihood estimation. For $x \\sim t_\u03bd(0,\\Sigma_t)$ and $x \\sim H_{\\chi,\\psi}(0,\\Sigma_H)$, parameters are estimated by a multi-cycle, expectation, conditional estimation algorithm (Breymann and L\u00fcthi, 2013). Then we use the plug-in estimators $\\hat{s}(\\cdot)$ and $\\hat{T}(\\cdot)$ to calculate $\\hat{B}$ and $\\tilde{B}$ defined by equation (2.8) and equation (2.11), respectively.\n\nI.5 Extended Experiments and Further Discussion\n\nIn this subsection, we provide results of experiments on additional choices of p in {50, 80, 100}, and p = 30 in the main paper, which are depicted in Figures S1 to S4. Except results similar to those discussed in Section 4.2, comparing Figures S1 to S4, we see that, while the second-order method tend to overwhelm other methods as the sample size increases, the minimum sample size that it needs to overtake others increases as p increases, which coincides with our analysis of the higher order dependency of its convergence rate on p in Section 3.2.\n\nI.6 Measures of Qualities of Estimates of Latent Spaces in Section 5\n\nSuppose image data X \u2208 \u211d\u1d9c\u02e3\u1d9c \u223c P(X), we have an encoder E(Z) : \u211d\u1d9c\u02e3\u1d9c \u2192 \u211d\u02b0, and a decoder D(z) : \u211d\u02b0 \u2192 \u211d\u1d9c\u02e3\u1d9c, where h denotes the embedding dimension. We first consider two metrics measuring (dis-)similarities between the original image X and the recovered image X\u0303 = D \u2218 E(X).\n\n1. We consider the normalized root squared error (NRSE), i.e., E_X(\u2225X\u0303 - X\u2225_F / \u2225X\u2225_F)\n\n2. We also consider the structural similarity index measure (SSIM) between X\u0303 and X, i.e., E_X{SSIM(X\u0303, X)}. SSIM calculates the similarity score between two images by comparing their luminance, contrast, and structure; it ranges from -1 to 1 and the larger the SSIM is, the more similar the images are. For the definition of SSIM, please refer to Section III.1.1 of the Supplement for details.\n\n3. Specifically, we consider the classification accuracy defined by:\n\nE[I{argmax \u2218 C_E \u2218 E(X) = y}],\n\nwhere I(\u00b7) is the indicator function and C_E(\u00b7) : \u211d\u02b0 \u2192 \u211d\u00b9\u2070 is a multinomial logistic regression model trained on the set [{E(X_i), y_i}]\u207f\u1d62\u208c\u2081. For details of the model C_E(\u00b7), please refer to Section III.1.2 of the Supplement.\n\nI.7 Application Details of Competing Methods in Section 5\n\nLet B\u0302_PCA = Eigen_h[var{vec(X)}]. For PCA method, we let the encoder to be E_PCA(X) = B\u0302\u1d40_PCA vec(X) and the decoder to be D_PCA(x) = vec\u207b\u00b9{B\u0302_PCA x}.\u00b3 We employ fully connected neural networks for AE, encoder E_AE,\u03b8\u2091(X) and decoder D_AE,\u03b8d(x), are parametrized by \u03b8_e and \u03b8_d respectively, which can be estimated by minimizing the reconstruction squared error loss. Empirically, (\u03b8\u0302_e, \u03b8\u0302_d) is the minimizer of the following loss function:\n\n$$\u2113(\u03b8_e, \u03b8_d) = \\frac{1}{n} \\sum_{i=1}^n \u2225D_{AE,\u03b8_d} \u2218 E_{AE,\u03b8_e}(X_i) - X_i\u2225\u00b2_F.$$\n\nWe also use batch-training methods to solve the optimization problem. For details of the structure of the AE and training procedures, please refer to Section III.1.3 of the Supplement.\n\n\u00b3Since pixel values of original images are in [0,1], we use the clip function clip(x, \u03b1, \u03b2) = min{max(x, \u03b1), \u03b2} to scale the output of the decoder. For fair comparison, we handle the range problem in the same way for all methods, instead of constraining the range of output in the structure of the decoder.\n\nFor our first-order estimator, we use the pre-trained score model for MNIST from Song and Ermon (2019) as our first-order score estimator denoted as $\\hat{s}(\u00b7)^4$. Then the plug-in estimator $\\hat{B}$ equals $\\text{SVD}_{l,h}[(1/n)\\sum_{i=1}^n \\text{vec}\\{\\hat{s}(X_i)\\}\\{\\text{vec}(X_i)\\}^\\top]$, and our first-order encoder is defined as $\\mathcal{E}_{S_f}(X) = \\hat{B}^\\top \\text{vec}(X)$. Our first-order decoder has the same structure as that of the AE, parametrized by $\\theta_{S_f}$ and denoted as $D_{S_f,\\theta_{S_f}}(\\cdot)$; $\\theta_{S_f}$ can also be estimated by minimizing the following empirical mean reconstruction squared error losses on the training set:\n\n$$\\ell(\\theta_{S_f}) = \\frac{1}{n}\\sum_{i=1}^n \\{||D_{S_f,\\theta_{S_f}} \\circ \\mathcal{E}_{S_f}(X_i) - X_i||_F^2\\} \\qquad (S8)$$\n\nThe decoder is trained in the way similar to that of the AE, please see Section III.1.3 of the Supplement for details.\n\nFor our second-order estimator, since there is a lack of trustworthy second-order score models as discussed in Section I.3, we assume pixel values in an vectorized image data follow a multivariate normal distribution and use the estimator of second-order stein's score of multivariate normal distribution introduced in Section II.4 as the second-order score estimator $\\hat{T}(\\cdot)$. We still use $\\tilde{B}$ to denote the second-order plug-in estimator, which equals $\\text{SVD}_{l,h}[(1/n/c^2\\sum_{i=1}^n \\sum_{j=1}^{c^2} \\text{vec}(X_i)_j\\hat{T}\\{\\text{vec}(X_i)\\}]$, and the second-order encoder is defined as $\\mathcal{E}_{S_s}(X) = \\tilde{B}^\\top \\text{vec}(X)$. The second order decoder $D_{S_s,\\theta_{S_s}}(X)$ has the same structure as the first-order decoder and is trained in the same way.",
        "sub_heading": "I.4 Reduced Rank Estimator, Neural Network Estimator and Ours",
        "collection_name": "pdf4",
        "similarity": 0.8028448820114136
    },
    {
        "text": "Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261\u20132285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52\u201372.\n\nBreymann, W. and L\u00fcthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693\u2013703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 \u2013 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817\u2013823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265\u2013286.\n\nHyv\u00e4rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695\u2013709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980\u20131000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241\u2013255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316\u2013327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein's lemma. Journal of the American Statistical Association 87 1025\u20131039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009\u20131052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163\u2013194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359\u201325369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612\u2013622.\n\nO'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26\u201359.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559\u2013572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144\u2013150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955\u2013963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769\u2013782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661\u20131674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore\u2013penrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein's method. Advances in Neural Information Processing Systems 30 6097\u20136106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis\u2013kahan theorem for statisticians. Biometrika 102 315\u2013323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329\u2013346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n\"Nonlinear Multiple Response Regression and Learning of Latent Spaces\"\n\nYe Tian, Sanyou Wu and Long Feng",
        "sub_heading": "References",
        "collection_name": "pdf4",
        "similarity": 0.8010231256484985
    },
    {
        "text": "Table S1 demonstrates the structure of the AE we use. The same decoder structure is also used for our method. To estimate the parameters of AE (\u03b8_e, \u03b8_d), we minimize the loss function (S7); and to estimate the parameters of decoders of our methods, we minimize the loss functions (S8). For both AE and our methods, we use the batch-training strategy to train the neural network. We use Adam optimizer with Pytorch default parameters. We choose the batch size to be 128 and we train the neural network for 50 epochs.\n\nTable S1: Structure of the Autoencoder\n\n| Layer | Type | Encoder | Decoder |\n|-------|------|---------|---------|\n| 1 | fully connected layer (in dims = 784, out dims = 4h) | \u2713 | \u2713 |\n| 2 | ReLU | \u2713 | \u2713 |\n| 3 | fully connected layer (in dims = 4h, out dims = 2h) | \u2713 | fully connected layer (in dims = 2h, out dims = 4h) |\n| 4 | ReLU | \u2713 | \u2713 |\n| 5 | fully connected layer (in dims = 2h, out dims = h) | \u2713 | fully connected layer (in dims = 4h, out dims = 784) |",
        "sub_heading": "III.1.3 Structure and Training Details of Autoencoder",
        "collection_name": "pdf4",
        "similarity": 0.8005106449127197
    },
    {
        "text": "As noted earlier, CNNs primarily focus on the basis that the input will be comprised of images. This focuses the architecture to be set up in way to best suit the need for dealing with the specific type of data.\n\n4      Keiron O\u2019Shea et al.\n\nOne of the key differences is that the neurons that the layers within the CNN\nare comprised of neurons organised into three dimensions, the spatial dimen-\nsionality of the input (height and the width) and the depth. The depth does not\nrefer to the total number of layers within the ANN, but the third dimension of a\nactivation volume. Unlike standard ANNS, the neurons within any given layer\nwill only connect to a small region of the layer preceding it.\nIn practice this would mean that for the example given earlier, the input \u2019vol-\nume\u2019 will have a dimensionality of 64 \u00d7 64 \u00d73 (height, width and depth), lead-\ning to a final output layer comprised of a dimensionality of 1 \u00d7 1 \u00d7 n (where\nn represents the possible number of classes) as we would have condensed the\nfull input dimensionality into a smaller volume of class scores filed across the\ndepth dimension.\n\n2.1  Overall architecture\n\nCNNs are comprised of three types of layers. These are convolutional layers,\npooling layers and fully-connected layers. When these layers are stacked, a\nCNN architecture has been formed. A simplified CNN architecture for MNIST\nclassification is illustrated in Figure 2.\n\nconvolution\nw/ReLu pooling     fully\u2011connected\n\n0\n...\n9\ninput                                    output\n\nfully\u2011connected\nw/ ReLu\n\nFig. 2: An simple CNN architecture, comprised of just five layers\n\nThe basic functionality of the example CNN above can be broken down into\nfour key areas.\n1. As found in other forms of ANN, the input layer will hold the pixel values\nof the image.\n2. The convolutional layer will determine the output of neurons of which are\nconnected to local regions of the input through the calculation of the scalar\nproduct between their weights and the region connected to the input vol-\nume. The rectified linear unit (commonly shortened to ReLu) aims to apply\n\nIntroduction to Convolutional Neural Networks    5\n\nan 'elementwise' activation function such as sigmoid to the output of the activation produced by the previous layer.\n\n3. The pooling layer will then simply perform downsampling along the spatial dimensionality of the given input, further reducing the number of parameters within that activation.\n\n4. The fully-connected layers will then perform the same duties found in standard ANNs and attempt to produce class scores from the activations, to be used for classification. It is also suggested that ReLu may be used between these layers, as to improve performance.\n\nThrough this simple method of transformation, CNNs are able to transform the original input layer by layer using convolutional and downsampling techniques to produce class scores for classification and regression purposes.\n\n| | | | | | | | | | | | | | |\n|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n| / | L | \u2022 | - | - | ) | / | - | - | ) | 6 | - | / | \\ |\n| 7 | | < | - | \\ | ) | ( | \u2022 | | - | ) | < | ) | \u2022 |\n| < | / | \\ | \\ | / | - | / | ( | ( | / | - | \\ | - | / |\n| \\ | ) | ( | - | < | ( | ) | - | / | \\ | ( | - | ( | ) |\n| - | | ) | ) | \\ | - | ) | - | | - | ( | | | |\n| / | 5 | - | ( | ( | - | ) | - | ( | / | ) | ) | - |\n\nFig. 3: Activations taken from the first convolutional layer of a simplistic deep CNN, after training on the MNIST database of handwritten digits. If you look carefully, you can see that the network has successfully picked up on characteristics unique to specific numeric digits.\n\nHowever, it is important to note that simply understanding the overall architecture of a CNN architecture will not suffice. The creation and optimisation of these models can take quite some time, and can be quite confusing. We will now explore in detail the individual layers, detailing their hyperparameters and connectivities.",
        "sub_heading": "2 CNN architecture",
        "collection_name": "cnn1",
        "similarity": 0.8361161947250366
    },
    {
        "text": "As the name implies, the convolutional layer plays a vital role in how CNNs operate. The layers parameters focus around the use of learnable kernels.\n\n6       Keiron O'Shea et al.\n\nThese kernels are usually small in spatial dimensionality, but spreads along the entirety of the depth of the input. When the data hits a convolutional layer, the layer convolves each filter across the spatial dimensionality of the input to produce a 2D activation map. These activation maps can be visualised, as seen in Figure 3.\n\nAs we glide through the input, the scalar product is calculated for each value in that kernel. (Figure 4) From this the network will learn kernels that 'fire' when they see a specific feature at a given spatial position of the input. These are commonly known as activations.\n\n| Input Vector |  |  |  |  |  | Pooled Vector |  |  | Kernel |  |  | Destination Pixel |\n|--------------|--|--|--|--|--|---------------|--|--|--------|--|--|-------------------|\n| 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 |  |\n| 0 | 1 | 2 | 1 | 1 | 2 | 0 | 1 | 2 | 0 | 0 | 0 | -8 |\n| 0 | 1 | 1 | 1 | 1 | 1 | 0 | 1 | 1 | 0 | 0 | -4 |  |\n| 1 | 0 | 0 | 0 | 0 | 0 |  |  |  |  |  |  |  |\n| 0 | 0 | 1 | 1 | 1 | 0 |  |  |  |  |  |  |  |\n| 0 | 1 | 1 | 1 | 1 | 1 |  |  |  |  |  |  |  |\n\nFig. 4: A visual representation of a convolutional layer. The centre element of the kernel is placed over the input vector, of which is then calculated and replaced with a weighted sum of itself and any nearby pixels.\n\nEvery kernel will have a corresponding activation map, of which will be stacked along the depth dimension to form the full output volume from the convolutional layer.\n\nAs we alluded to earlier, training ANNs on inputs such as images results in models of which are too big to train effectively. This comes down to the fully-connected manner of standard ANN neurons, so to mitigate against this every neuron in a convolutional layer is only connected to small region of the input volume. The dimensionality of this region is commonly referred to as the receptive field size of the neuron. The magnitude of the connectivity through the depth is nearly always equal to the depth of the input.\n\nFor example, if the input to the network is an image of size 64 \u00d7 64 \u00d7 3 (a RGB-coloured image with a dimensionality of 64 \u00d7 64) and we set the receptive field size as 6 \u00d7 6, we would have a total of 108 weights on each neuron within the convolutional layer. (6 \u00d7 6 \u00d7 3 where 3 is the magnitude of connectivity across the depth of the volume) To put this into perspective, a standard neuron seen in other forms of ANN would contain 12,288 weights each.\n\nConvolutional layers are also able to significantly reduce the complexity of the model through the optimisation of its output. These are optimised through three hyperparameters, the depth, the stride and setting zero-padding.\n\nIntroduction to Convolutional Neural Networks    7\n\nThe depth of the output volume produced by the convolutional layers can be manually set through the number of neurons within the layer to a the same region of the input. This can be seen with other forms of ANNs, where the all of the neurons in the hidden layer are directly connected to every single neuron beforehand. Reducing this hyperparameter can significantly minimise the total number of neurons of the network, but it can also significantly reduce the pattern recognition capabilities of the model.\n\nWe are also able to define the stride in which we set the depth around the spatial dimensionality of the input in order to place the receptive field. For example if we were to set a stride as 1, then we would have a heavily overlapped receptive field producing extremely large activations. Alternatively, setting the stride to a greater number will reduce the amount of overlapping and produce an output of lower spatial dimensions.\n\nZero-padding is the simple process of padding the border of the input, and is an effective method to give further control as to the dimensionality of the output volumes.\n\nIt is important to understand that through using these techniques, we will alter the spatial dimensionality of the convolutional layers output. To calculate this, you can make use of the following formula:\n\n$$(V - R) + 2Z \\over S + 1$$\n\nWhere V represents the input volume size (height\u00d7width\u00d7depth), R represents the receptive field size, Z is the amount of zero padding set and S referring to the stride. If the calculated result from this equation is not equal to a whole integer then the stride has been incorrectly set, as the neurons will be unable to fit neatly across the given input.\n\nDespite our best efforts so far we will still find that our models are still enormous if we use an image input of any real dimensionality. However, methods have been developed as to greatly curtail the overall number of parameters within the convolutional layer.\n\nParameter sharing works on the assumption that if one region feature is useful to compute at a set spatial region, then it is likely to be useful in another region. If we constrain each individual activation map within the output volume to the same weights and bias, then we will see a massive reduction in the number of parameters being produced by the convolutional layer.\n\nAs a result of this as the backpropagation stage occurs, each neuron in the output will represent the overall gradient of which can be totalled across the depth - thus only updating a single set of weights, as opposed to every single one.\n\n8      Keiron O'Shea et al.",
        "sub_heading": "2.2 Convolutional layer",
        "collection_name": "cnn1",
        "similarity": 0.826104998588562
    },
    {
        "text": "1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642\u20133649. IEEE (2012)\n\n2. Cire\u015fan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013, pp. 411\u2013418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire\u015fan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135\u20131139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279\u20132301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257\u2013260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221\u2013231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725\u20131732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097\u20131105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541\u2013551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278\u20132324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685\u2013696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224\u2013229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553\u20132561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157\u20132162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision\u2013ECCV 2014, pp. 818\u2013833. Springer (2014)",
        "sub_heading": "References",
        "collection_name": "cnn1",
        "similarity": 0.8010231256484985
    }
]

            Note:  Do not include text like I understand or here is your summary and Do not mension heading at start.
            Output Format:
            Provide a concise, headding and well-structured, contextually relevant summary based on the retrieved texts.
            in fornt of heading put a 2nd Heading (##) like Markdown format and then nextline then summary normal text give it as usual, Multiple "sub-headding" could have same heading so provide multiple heading and summries but they should not be same.
        