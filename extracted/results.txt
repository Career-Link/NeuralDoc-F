{
    "Results": {
        "cnn1": [
            {
                "text": "1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642\u20133649. IEEE (2012)\n\n2. Cire\u015fan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013, pp. 411\u2013418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire\u015fan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135\u20131139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279\u20132301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257\u2013260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221\u2013231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725\u20131732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097\u20131105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541\u2013551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278\u20132324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685\u2013696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224\u2013229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553\u20132561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157\u20132162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision\u2013ECCV 2014, pp. 818\u2013833. Springer (2014)",
                "similarity": 0.8521066904067993
            }
        ],
        "cnn3": [
            {
                "text": "We first report the configuration which achieved the highest accuracy, followed by the search through the space of hyperparameters (using only our validation data set) leading to the optimal configuration. We close by demonstrating the ability of FF trained CNNs to implement Class Activation Maps, which is a method from the explainable AI toolbox.",
                "similarity": 0.9046024084091187
            }
        ],
        "cnn5": [
            {
                "text": "1. Cheng, Qisen and Qu, Shuhui and Lee, Janghwan. \"72-3: Deep Learning Based Visual Defect Detection in Noisy and Imbalanced Data.\" SID Symposium Digest of Technical Papers, vol. 53, no. 1, pp. 971-974, 2022.\n\n2. Cheng, Qisen and Zhang, Chang and Shen, Xiang. \"Estimation of Energy and Time Usage in 3D Printing With Multimodal Neural Network.\" 2022 4th International Conference on Frontiers Technology of Information and Computer (ICFTIC), pp. 900-903, 2022.\n\n3. Cifar10 Dataset. [online]. Avaiable:https://www.cs.toronto.edu/ kriz/cifar.html.\n\n4. Xing, Jinming. \"Enhancing Link Prediction with Fuzzy Graph Attention Networks and Dynamic Negative Sampling.\" arXiv preprint arXiv:2411.07482 (2024).\n\n5. Veli\u010dkovi\u0107, Petar, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. \"Graph attention networks.\" arXiv preprint arXiv:1710.10903 (2017).\n\n6. Hamilton, Will, Zhitao Ying, and Jure Leskovec. \"Inductive representation learning on large graphs.\" Advances in neural information processing systems 30 (2017).\n\n7. Xing, Jinming, Can Gao, and Jie Zhou. \"Weighted fuzzy rough sets-based tri-training and its application to medical diagnosis.\" Applied Soft Computing 124 (2022): 109025.\n\n8. Gao, Can, Jie Zhou, Jinming Xing, and Xiaodong Yue. \"Parameterized maximum-entropy-based three-way approximate attribute reduction.\" International Journal of Approximate Reasoning 151 (2022): 85-100.\n\n9. Xing, Jinming, Ruilin Xing, and Yan Sun. \"FGATT: A Robust Framework for Wireless Data Imputation Using Fuzzy Graph Attention Networks and Transformer Encoders.\" arXiv preprint arXiv:2412.01979 (2024).\n\n10. S. R. Livingstone and F. A. Russo, \"The Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS),\" PloS one, vol. 13, no. 5, p. e0196391, 2018. Available: https://zenodo.org/record/1188976\n\n11. Xing, Jinming, Dongwen Luo, Qisen Cheng, Chang Xue, and Ruilin Xing. \"Multi-view Fuzzy Graph Attention Networks for Enhanced Graph Learning.\" arXiv preprint arXiv:2412.17271 (2024).\n\n12. G. Heigold, I. L. Moreno, S. Bengio, and N. Shazeer, \"End-to-End Text-Dependent Speaker Verification,\" in Proceedings of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2016, pp. 5115\u20135119.\n\n13. S. Hochreiter and J. Schmidhuber, \"Long Short-Term Memory,\" Neural Computation, vol. 9, no. 8, pp. 1735\u20131780, 1997.\n\n14. F. A. Gers, J. Schmidhuber, and F. Cummins, \"Learning to Forget: Continual Prediction with LSTM,\" Neural Computation, vol. 12, no. 10, pp. 2451\u20132471, 2000.\n\n15. Xing, Jinming, Ruilin Xing, and Yan Sun. \"Comparative Analysis of Pooling Mechanisms in LLMs: A Sentiment Analysis Perspective.\" arXiv preprint arXiv:2411.14654 (2024).",
                "similarity": 0.8521066904067993
            }
        ],
        "pdf2": [
            {
                "text": "Table A.1: Test performance metrics for various RNA-related tasks.\n\n| Task       | Test F1-Score | Test AUC | Test Global Balanced Accuracy | Test MCC | Test Jaccard |\n|------------|---------------|----------|-------------------------------|----------|--------------|\n| RNA_Ligand | 0.2771        | 0.6751   | 0.4678                        |          |              |\n| RNA_CM     | 0.1957        | 0.7393   | 0.6615                        | 0.1695   |              |\n| RNA_Site   | 0.3346        | 0.5929   | 0.6309                        | 0.3098   |              |\n| RNA_Prot   | 0.4545        | 0.6654   | 0.6254                        | 0.2469   |              |\n| RNA_IF     | 0.3326        | 0.6201   | 0.3523*                       | 0.1319   |              |\n| RNA_VS     |               | 0.855    |                               |          |              |\n| RNA_GO     | 0.4074        | 0.8406   | 0.7067                        |          | 0.3167       |\n\nHyperparameters used:\n- RNA_Ligand: n_layers=4, hidden_dim=128, lr=0.00001, dropout=0.5\n- RNA_CM: n_layers=3, hidden_dim=128, lr=0.001, dropout=0.5\n- RNA_Site: n_layers=4, hidden_dim=256, lr=0.001, dropout=0.5\n- RNA_Prot: n_layers=4, hidden_dim=64, lr=0.01, dropout=0.2\n- RNA_IF: n_layers=3, hidden_dim=128, lr=0.0001, dropout=0.5\n- RNA_VS: n_layers=3, hidden_dim=64/32, lr=0.001, dropout=0.2\n- RNA_GO: n_layers=3, hidden_dim=64, lr=0.001, dropout=0.5\n\n\\* For RNA_IF, the reported value in \"Global Balanced Accuracy\" is sequence recovery.\n\nTable A.2: We compare a standard RGCN using the rnaglib's task module with various published results using the TR60/TE18 split. Note: Binding site definitions may vary slightly between models.\n\n| Methods                   | MCC   | AUC   |\n|---------------------------|-------|-------|\n| Rsite2 (Zeng & Cui, 2016) | 0.010 | 0.474 |\n| Rsite (Zeng et al., 2015) | 0.055 | 0.496 |\n| RBind (Wang et al., 2018) | 0.141 | 0.540 |\n| RNAsite_seq (Su et al., 2021) | 0.160 | 0.641 |\n| RNAsite_str (Su et al., 2021) | 0.185 | 0.695 |\n| RNAsite (Su et al., 2021) | 0.186 | 0.703 |\n| rnaglib RNA-Site          | 0.113 | 0.606 |\n\nTable A.3: Sequence recovery scores for RNA inverse folding models. We use a standard two layer RGCN part of rnaglib's task module on the dataset and split published by Joshi et al. (2024)\n\n| Method                         | Sequence Recovery |\n|--------------------------------|-------------------|\n| gRNAde (Joshi et al., 2024)    | 0.568             |\n| Rosetta (Leman et al., 2020b)  | 0.450             |\n| RDesign (Tan et al., 2023)     | 0.430             |\n| FARNA (Alam et al., 2017)      | 0.321             |\n| ViennaRNA (Lorenz et al., 2011)| 0.269             |\n| rnaglib RNA-IF                 | 0.410             |",
                "similarity": 0.8574557304382324
            }
        ],
        "pdf4": [
            {
                "text": "Balasubramanian, K., Fan, J. and Yang, Z. (2018). Tensor methods for additive index models under discordance and heterogeneity. arXiv preprint arXiv:1807.06693 .\n\nBauer, B. and Kohler, M. (2019). On deep learning as a remedy for the curse of dimensionality in nonparametric regression. The Annals of Statistics 47 2261\u20132285.\n\nBauer, F., Pereverzev, S. and Rosasco, L. (2007). On regularization algorithms in learning theory. Journal of complexity 23 52\u201372.\n\nBreymann, W. and L\u00fcthi, D. (2013). ghyp: A package on generalized hyperbolic distributions. Manual for R Package ghyp .\n\nCandes, E. J., Li, X., Ma, Y. and Wright, J. (2009). Robust principal component analysis? arXiv preprint arXiv: 0912.3599 .\n\nChangliang Zou, Y. K. and Zhang, W. (2022). Estimation of low rank high-dimensional multivariate linear models for multi-response data. Journal of the American Statistical Association 117 693\u2013703.\n\nChen, K., Dong, H. and Chan, K.-S. (2012). Reduced rank regression via adaptive nuclear norm penalization. arXiv preprint arXiv:1201.0381 .\n\nChen, X., Zou, C. and Cook, R. D. (2010). Coordinate-independent sparse sufficient dimension reduction and variable selection. The Annals of Statistics 38 3696 \u2013 3723.\n\nDamian, A., Lee, J. and Soltanolkotabi, M. (2022). Neural networks can learn representations with gradient descent. In Conference on Learning Theory.\n\nFriedman, J. H. and Stuetzle, W. (1981). Projection pursuit regression. Journal of the American Statistical Association 76 817\u2013823.\n\nHui Zou, T. H. and Tibshirani, R. (2006). Sparse principal component analysis. Journal of Computational and Graphical Statistics 15 265\u2013286.\n\nHyv\u00e4rinen, A. and Dayan, P. (2005). Estimation of non-normalized statistical models by score matching. Journal of Machine Learning Research 6 695\u2013709.\n\nJanzamin, M., Sedghi, H. and Anandkumar, A. (2014). Score function features for discriminative learning: Matrix and tensor framework. arXiv preprint arXiv:1412.2863 .\n\nKobak, D., Bernaerts, Y., Weis, M. A., Scala, F., Tolias, A. S. and Berens, P. (2021). Sparse reduced-rank regression for exploratory visualisation of paired multivariate data. Journal of the Royal Statistical Society Series C: Applied Statistics 70 980\u20131000.\n\nLee, W. and Liu, Y. (2012). Simultaneous multiple response regression and inverse covariance matrix estimation via penalized gaussian maximum likelihood. Journal of Multivariate Analysis 111 241\u2013255.\n\nLi, K.-C. (1991). Sliced inverse regression for dimension reduction. Journal of the American Statistical Association 86 316\u2013327.\n\nLi, K.-C. (1992). On principal hessian directions for data visualization and dimension reduction: Another application of stein's lemma. Journal of the American Statistical Association 87 1025\u20131039.\n\nLi, K.-C. and Duan, N. (1989). Regression analysis under link violation. The Annals of Statistics 1009\u20131052.\n\nLi, Y. and Turner, R. E. (2017). Gradient estimators for implicit models. arXiv preprint arXiv:1705.07107 .\n\nLu, Z., Monteiro, R. D. and Yuan, M. (2012). Convex optimization methods for dimension reduction and coefficient estimation in multivariate linear regression. Mathematical Programming 131 163\u2013194.\n\nMakhzani, A. and Frey, B. (2013). K-sparse autoencoders. arXiv preprint arXiv:1312.5663 .\n\nMeng, C., Song, Y., Li, W. and Ermon, S. (2021). Estimating high order gradients of the data distribution by denoising. Advances in Neural Information Processing Systems 34 25359\u201325369.\n\nMousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. and Erdogdu, M. A. (2022).\nNeural networks efficiently learn low-dimensional representations with sgd. arXiv preprint\narXiv:2209.14863 .\n\nMukherjee, A. and Zhu, J. (2011). Reduced rank ridge regression and its kernel extensions.\nStatistical analysis and data mining: the ASA data science journal 4 612\u2013622.\n\nO'Rourke, S., Vu, V. and Wang, K. (2018). Random perturbation of low rank matrices:\nImproving classical bounds. Linear Algebra and its Applications 540 26\u201359.\n\nPearson, K. (1901). Liii. on lines and planes of closest fit to systems of points in space. The\nLondon, Edinburgh, and Dublin philosophical magazine and journal of science 2 559\u2013572.\n\nRifai, S., Vincent, P., Muller, X., Glorot, X. and Bengio, Y. (2011). Contractive auto-\nencoders: Explicit invariance during feature extraction. In Proceedings of the 28th international\nconference on international conference on machine learning.\n\nScala, F., Kobak, D., Bernabucci, M., Bernaerts, Y., Cadwell, C. R., Castro, J. R.,\nHartmanis, L., Jiang, X., Laturnus, S., Miranda, E. et al. (2021). Phenotypic variation\nof transcriptomic cell types in mouse motor cortex. Nature 598 144\u2013150.\n\nShi, J., Sun, S. and Zhu, J. (2018). A spectral approach to gradient estimation for implicit\ndistributions. In International Conference on Machine Learning.\n\nSimon, N., Friedman, J. and Hastie, T. (2013). A blockwise descent algorithm for group-\npenalized multiresponse and multinomial regression. arXiv preprint arXiv:1311.6529 .\n\nSong, Y. and Ermon, S. (2019). Generative modeling by estimating gradients of the data\ndistribution. Advances in neural information processing systems 32.\n\nSong, Y., Garg, S., Shi, J. and Ermon, S. (2020). Sliced score matching: A scalable approach\nto density and score estimation. In Uncertainty in Artificial Intelligence.\n\nStrathmann, H., Sejdinovic, D., Livingstone, S., Szabo, Z. and Gretton, A. (2015).\nGradient-free hamiltonian monte carlo with efficient kernel exponential families. Advances in\nNeural Information Processing Systems 28 955\u2013963.\n\nTan, K. M., Wang, Z., Zhang, T., Liu, H. and Cook, R. D. (2018). A convex formulation for\nhigh-dimensional sparse sliced inverse regression. Biometrika 105 769\u2013782.\n\nVershynin, R. (2018a). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVershynin, R. (2018b). High-dimensional probability: An introduction with applications in data\nscience, vol. 47. Cambridge university press.\n\nVincent, P. (2011). A connection between score matching and denoising autoencoders. Neural\ncomputation 23 1661\u20131674.\n\nVincent, P., Larochelle, H., Bengio, Y. and Manzagol, P.-A. (2008). Extracting and\ncomposing robust features with denoising autoencoders. In Proceedings of the 25th international\nconference on Machine learning.\n\nWANG, W., LIANG, Y. and XING, E. (2013). Block regularized lasso for multivariate multi-response linear regression. In Artificial intelligence and statistics.\n\nXU, X. (2020). On the perturbation of the moore\u2013penrose inverse of a matrix. Applied Mathematics and Computation 374 124920.\n\nYANG, Z., BALASUBRAMANIAN, K. and LIU, H. (2017a). High-dimensional non-Gaussian single index models via thresholded score function estimation. In Proceedings of the 34th International Conference on Machine Learning, vol. 70.\n\nYANG, Z., BALASUBRAMANIAN, K., WANG, Z. and LIU, H. (2017b). Learning non-gaussian multi-index model via second-order stein's method. Advances in Neural Information Processing Systems 30 6097\u20136106.\n\nYU, Y., WANG, T. and SAMWORTH, R. J. (2015). A useful variant of the davis\u2013kahan theorem for statisticians. Biometrika 102 315\u2013323.\n\nYUAN, M., EKICI, A., LU, Z. and MONTEIRO, R. (2007). Dimension reduction and coefficient estimation in multivariate linear regression. Journal of the Royal Statistical Society Series B: Statistical Methodology 69 329\u2013346.\n\nZHOU, Y., SHI, J. and ZHU, J. (2020). Nonparametric score estimators. In International Conference on Machine Learning.\n\n17\n\nSupplementary Material for\n\"Nonlinear Multiple Response Regression and Learning of Latent Spaces\"\n\nYe Tian, Sanyou Wu and Long Feng",
                "similarity": 0.8521066904067993
            }
        ],
        "cnn2": [
            {
                "text": "[1] Joakim And\u00e9n and St\u00e9phane Mallat. Deep scattering spectrum. Signal Processing, IEEE Transactions on, 62(16):4114\u20134128, 2014.\n\n[2] Joan Bruna and St\u00e9phane Mallat. Invariant scattering convolution networks. Pattern Analysis and Machine Intelligence, IEEE Transactions on, 35(8):1872\u20131886, 2013.\n\n[3] Corinna Cortes and Vladimir Vapnik. Support-vector networks. Machine learning, 20(3): 273\u2013297, 1995.\n\n[4] Joan Bruna Estrach. Scattering representations for recognition.\n\n[5] Kaiser Gerald. A friendly guide to wavelets, 1994.\n\n[6] B Boser Le Cun, John S Denker, D Henderson, Richard E Howard, W Hubbard, and Lawrence D Jackel. Handwritten digit recognition with a back-propagation network. In Advances in neural information processing systems. Citeseer, 1990.\n\n[7] Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278\u20132324, 1998.\n\n[8] Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. Nature, 521(7553):436\u2013444, 2015.\n\n[9] St\u00e9phane Mallat. Group invariant scattering. Communications on Pure and Applied Mathematics, 65(10):1331\u20131398, 2012.\n\n[10] St\u00e9phane Mallat. Understanding deep convolutional networks. arXiv preprint arXiv:1601.04920, 2016.",
                "similarity": 0.8521066904067993
            }
        ],
        "cnn4": [
            {
                "text": "The results of our trials can be found in Figure 3 and a comparison of our model with other models on CIFAR-10 image classification can be found in Figure 4.\n\nFigure 3: Table displaying the number of parameters required to achieve different validation accuracies on CIFAR-10 over 5 different trials with the same hyperparameters.\n\n| Metric | Trial 1 | Trial 2 | Trial 3 | Trial 4 | Trial 5 | Mean |\n|--------|---------|---------|---------|---------|---------|------|\n| Val Accuracy (at 70%) | 13696 | 11360 | 11360 | 11360 | 9024 | 11360.0 |\n| Val Accuracy (at 80%) | 27852 | 51880 | 22636 | 37320 | 28588 | 33655.2 |\n| Highest Val Accuracy (%) | 83.4 | 84.6 | 84.6 | 84.5 | 83.2 | 84.1 |\n| Parameters at Highest Accuracy | 74564 | 73720 | 57808 | 66440 | 40960 | 62698.4 |",
                "similarity": 0.9121243953704834
            }
        ],
        "pdf1": [
            {
                "text": "[1] J. Nicholson and A. Healey, \"The present state of autonomous underwater vehicle (AUV) applications and technologies,\" Marine Technology Society Journal, vol. 42, no. 1, pp. 44\u201351, 2008.\n\n[2] G. Griffiths, Technology and applications of autonomous underwater vehicles, vol. 2. CRC Press, 2002.\n\n[3] P. A. Miller, J. A. Farrell, Y. Zhao, and V. Djapic, \"Autonomous underwater vehicle navigation,\" IEEE Journal of Oceanic Engineering, vol. 35, no. 3, pp. 663\u2013678, 2010.\n\n[4] D. Rudolph and T. A. Wilson, \"Doppler Velocity Log theory and preliminary considerations for design and construction,\" in 2012 Proceedings of IEEE Southeastcon, pp. 1\u20137, IEEE, 2012.\n\n[5] N. Cohen and I. Klein, \"Inertial navigation meets deep learning: A survey of current trends and future directions,\" Results in Engineering, p. 103565, 2024.\n\n[6] F. Zhang, S. Zhao, L. Li, and C. Cao, \"Underwater DVL Optimization Network (UDON): A Learning-Based DVL Velocity Optimizing Method for Underwater Navigation,\" Drones, vol. 9, no. 1, p. 56, 2025.\n\n[7] Liu, Peijia and Wang, Bo and Li, Guanghua and Hou, Dongdong and Zhu, Zhengyu and Wang, Zhongyong, \"Sins/dvl integrated navigation method with current compensation using rbf neural network,\" IEEE Sensors Journal, vol. 22, no. 14, pp. 14366\u201314377, 2022.\n\n[8] E. Topini, F. Fanelli, A. Topini, M. Pebody, A. Ridolfi, A. B. Phillips, and B. Allotta, \"An experimental comparison of Deep Learning strategies for AUV navigation in DVL-denied environments,\" Ocean Engineering, vol. 274, p. 114034, 2023.\n\n[9] R. Makam, M. Pramuk, S. Thomas, and S. Sundaram, \"Spectrally Normalized Memory Neuron Network Based Navigation for Autonomous Underwater Vehicles in DVL-Denied Environment,\" in OCEANS 2024-Singapore, pp. 1\u20136, IEEE, 2024.\n\n[10] Z. Yampolsky and I. Klein, \"DCNet: A data-driven framework for DVL calibration,\" Applied Ocean Research, vol. 158, p. 104525, 2025.\n\n[11] M. Yona and I. Klein, \"MissBeamNet: Learning missing Doppler velocity log beam measurements,\" Neural Computing and Applications, vol. 36, no. 9, pp. 4947\u20134958, 2024.\n\n[12] N. Cohen, Z. Yampolsky, and I. Klein, \"Set-transformer BeamsNet for AUV velocity forecasting in complete DVL outage scenarios,\" in 2023 IEEE Underwater Technology (UT), pp. 1\u20136, IEEE, 2023.\n\n[13] N. Cohen and I. Klein, \"BeamsNet: A data-driven approach enhancing Doppler velocity log measurements for autonomous underwater vehicle navigation,\" Engineering Applications of Artificial Intelligence, vol. 114, p. 105216, 2022.\n\n[14] N. Cohen and I. Klein, \"Adaptive Kalman-Informed Transformer,\" Engineering Applications of Artificial Intelligence, vol. 146, p. 110221, 2025.\n\n[15] A. Levy and I. Klein, \"Adaptive Neural Unscented Kalman Filter,\" arXiv preprint arXiv:2503.05490, 2025.\n\n[16] Y. Stolero and I. Klein, \"AUV Acceleration Prediction Using DVL and Deep Learning ,\" arXiv preprint arXiv: 2503.16573, 2025.\n\n[17] D. Simon, Optimal state estimation: Kalman, H infinity, and nonlinear approaches. John Wiley & Sons, 2006.\n\n[18] Y. Bar-Shalom, X. R. Li, and T. Kirubarajan, Estimation with applications to tracking and navigation: theory algorithms and software. John Wiley & Sons, 2004.\n\n[19] P. Groves, Principles of GNSS, Inertial, and Multisensor Integrated Navigation Systems, Second Edition. GNSS/GPS, Artech House, 2013.\n\n[20] J. Farrell, Aided navigation: GPS with high rate sensors. McGraw-Hill, Inc., 2008.",
                "similarity": 0.8521066904067993
            }
        ],
        "pdf3": [
            {
                "text": "",
                "similarity": 0.8973236083984375
            }
        ]
    }
}