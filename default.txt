{
    "Introduction": {
        "cnn1": [
            {
                "text": "Artificial Neural Networks (ANNs) are computational processing systems of which are heavily inspired by way biological nervous systems (such as the human brain) operate. ANNs are mainly comprised of a high number of interconnected computational nodes (referred to as neurons), of which work entwine in a distributed fashion to collectively learn from the input in order to optimise its final output.\n\nThe basic structure of a ANN can be modelled as shown in Figure 1. We would load the input, usually in the form of a multidimensional vector to the input layer of which will distribute it to the hidden layers. The hidden layers will then make decisions from the previous layer and weigh up how a stochastic change within itself detriments or improves the final output, and this is referred to as the process of learning. Having multiple hidden layers stacked upon each-other is commonly called deep learning.\n\n2      Keiron O\u2019Shea et al.\n\nInput Layer    Hidden Layer   Output Layer\n\nInput 1\n\nInput 2\nOutput\n\nInput 3\n\nInput 4\n\nFig. 1: A simple three layered feedforward neural network (FNN), comprised\nof a input layer, a hidden layer and an output layer. This structure is the basis\nof a number of common ANN architectures, included but not limited to Feed-\nforward Neural Networks (FNN), Restricted Boltzmann Machines (RBMs) and\nRecurrent Neural Networks (RNNs).\n\nThe two key learning paradigms in image processing tasks are supervised and\nunsupervised learning. Supervised learning is learning through pre-labelled\ninputs, which act as targets. For each training example there will be a set of\ninput values (vectors) and one or more associated designated output values.\nThe goal of this form of training is to reduce the models overall classification\nerror, through correct calculation of the output value of training example by\ntraining.\n\nUnsupervised learning differs in that the training set does not include any la-\nbels. Success is usually determined by whether the network is able to reduce or\nincrease an associated cost function. However, it is important to note that most\nimage-focused pattern-recognition tasks usually depend on classification using\nsupervised learning.\n\nConvolutional Neural Networks (CNNs) are analogous to traditional ANNs\nin that they are comprised of neurons that self-optimise through learning. Each\nneuron will still receive an input and perform a operation (such as a scalar\nproduct followed by a non-linear function) - the basis of countless ANNs. From\nthe input raw image vectors to the final output of the class score, the entire of\nthe network will still express a single perceptive score function (the weight).\nThe last layer will contain loss functions associated with the classes, and all of\nthe regular tips and tricks developed for traditional ANNs still apply.\n\nThe only notable difference between CNNs and traditional ANNs is that CNNs\nare primarily used in the field of pattern recognition within images. This allows\nus to encode image-specific features into the architecture, making the network\n\nIntroduction to Convolutional Neural Networks    3\n\nmore suited for image-focused tasks - whilst further reducing the parameters required to set up the model.\n\nOne of the largest limitations of traditional forms of ANN is that they tend to struggle with the computational complexity required to compute image data. Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN, due to its relatively small image dimensionality of just 28 \u00d7 28. With this dataset a single neuron in the first hidden layer will contain 784 weights (28 \u00d7 28 \u00d7 1 where 1 bare in mind that MNIST is normalised to just black and white values), which is manageable for most forms of ANN.\n\nIf you consider a more substantial coloured image input of 64 \u00d7 64, the number of weights on just a single neuron of the first layer increases substantially to 12,288. Also take into account that to deal with this scale of input, the network will also need to be a lot larger than one used to classify colour-normalised MNIST digits, then you will understand the drawbacks of using such models.",
                "similarity": 0.9304435849189758
            }
        ]
    },
    "Abstract": {
        "cnn1": [
            {
                "text": "Artificial Neural Networks (ANNs) are computational processing systems of which are heavily inspired by way biological nervous systems (such as the human brain) operate. ANNs are mainly comprised of a high number of interconnected computational nodes (referred to as neurons), of which work entwine in a distributed fashion to collectively learn from the input in order to optimise its final output.\n\nThe basic structure of a ANN can be modelled as shown in Figure 1. We would load the input, usually in the form of a multidimensional vector to the input layer of which will distribute it to the hidden layers. The hidden layers will then make decisions from the previous layer and weigh up how a stochastic change within itself detriments or improves the final output, and this is referred to as the process of learning. Having multiple hidden layers stacked upon each-other is commonly called deep learning.\n\n2      Keiron O\u2019Shea et al.\n\nInput Layer    Hidden Layer   Output Layer\n\nInput 1\n\nInput 2\nOutput\n\nInput 3\n\nInput 4\n\nFig. 1: A simple three layered feedforward neural network (FNN), comprised\nof a input layer, a hidden layer and an output layer. This structure is the basis\nof a number of common ANN architectures, included but not limited to Feed-\nforward Neural Networks (FNN), Restricted Boltzmann Machines (RBMs) and\nRecurrent Neural Networks (RNNs).\n\nThe two key learning paradigms in image processing tasks are supervised and\nunsupervised learning. Supervised learning is learning through pre-labelled\ninputs, which act as targets. For each training example there will be a set of\ninput values (vectors) and one or more associated designated output values.\nThe goal of this form of training is to reduce the models overall classification\nerror, through correct calculation of the output value of training example by\ntraining.\n\nUnsupervised learning differs in that the training set does not include any la-\nbels. Success is usually determined by whether the network is able to reduce or\nincrease an associated cost function. However, it is important to note that most\nimage-focused pattern-recognition tasks usually depend on classification using\nsupervised learning.\n\nConvolutional Neural Networks (CNNs) are analogous to traditional ANNs\nin that they are comprised of neurons that self-optimise through learning. Each\nneuron will still receive an input and perform a operation (such as a scalar\nproduct followed by a non-linear function) - the basis of countless ANNs. From\nthe input raw image vectors to the final output of the class score, the entire of\nthe network will still express a single perceptive score function (the weight).\nThe last layer will contain loss functions associated with the classes, and all of\nthe regular tips and tricks developed for traditional ANNs still apply.\n\nThe only notable difference between CNNs and traditional ANNs is that CNNs\nare primarily used in the field of pattern recognition within images. This allows\nus to encode image-specific features into the architecture, making the network\n\nIntroduction to Convolutional Neural Networks    3\n\nmore suited for image-focused tasks - whilst further reducing the parameters required to set up the model.\n\nOne of the largest limitations of traditional forms of ANN is that they tend to struggle with the computational complexity required to compute image data. Common machine learning benchmarking datasets such as the MNIST database of handwritten digits are suitable for most forms of ANN, due to its relatively small image dimensionality of just 28 \u00d7 28. With this dataset a single neuron in the first hidden layer will contain 784 weights (28 \u00d7 28 \u00d7 1 where 1 bare in mind that MNIST is normalised to just black and white values), which is manageable for most forms of ANN.\n\nIf you consider a more substantial coloured image input of 64 \u00d7 64, the number of weights on just a single neuron of the first layer increases substantially to 12,288. Also take into account that to deal with this scale of input, the network will also need to be a lot larger than one used to classify colour-normalised MNIST digits, then you will understand the drawbacks of using such models.",
                "similarity": 0.8390400409698486
            }
        ]
    },
    "Conclusion": {
        "cnn1": [
            {
                "text": "Convolutional Neural Networks differ to other forms of Artifical Neural Network in that instead of focusing on the entirety of the problem domain, knowledge about the specific type of input is exploited. This in turn allows for a much simpler network architecture to be set up.\n\nThis paper has outlined the basic concepts of Convolutional Neural Networks, explaining the layers required to build one and detailing how best to structure the network in most image analysis tasks.\n\nResearch in the field of image analysis using neural networks has somewhat slowed in recent times. This is partly due to the incorrect belief surrounding the level of complexity and knowledge required to begin modelling these superbly powerful machine learning algorithms. The authors hope that this paper has in some way reduced this confusion, and made the field more accessible to beginners.",
                "similarity": 0.9333658218383789
            }
        ]
    },
    "References": {
        "cnn1": [
            {
                "text": "1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642\u20133649. IEEE (2012)\n\n2. Cire\u015fan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013, pp. 411\u2013418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire\u015fan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135\u20131139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279\u20132301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257\u2013260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221\u2013231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725\u20131732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097\u20131105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541\u2013551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278\u20132324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685\u2013696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224\u2013229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553\u20132561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157\u20132162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision\u2013ECCV 2014, pp. 818\u2013833. Springer (2014)",
                "similarity": 1.0000001192092896
            }
        ]
    },
    "Methodology": {
        "cnn1": [
            {
                "text": "Convolutional Neural Networks differ to other forms of Artifical Neural Network in that instead of focusing on the entirety of the problem domain, knowledge about the specific type of input is exploited. This in turn allows for a much simpler network architecture to be set up.\n\nThis paper has outlined the basic concepts of Convolutional Neural Networks, explaining the layers required to build one and detailing how best to structure the network in most image analysis tasks.\n\nResearch in the field of image analysis using neural networks has somewhat slowed in recent times. This is partly due to the incorrect belief surrounding the level of complexity and knowledge required to begin modelling these superbly powerful machine learning algorithms. The authors hope that this paper has in some way reduced this confusion, and made the field more accessible to beginners.",
                "similarity": 0.8373116850852966
            }
        ]
    },
    "Results": {
        "cnn1": [
            {
                "text": "1. Ciresan, D., Meier, U., Schmidhuber, J.: Multi-column deep neural networks for image classification. In: Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on. pp. 3642\u20133649. IEEE (2012)\n\n2. Cire\u015fan, D.C., Giusti, A., Gambardella, L.M., Schmidhuber, J.: Mitosis detection in breast cancer histology images with deep neural networks. In: Medical Image Computing and Computer-Assisted Intervention\u2013MICCAI 2013, pp. 411\u2013418. Springer (2013)\n\n3. Ciresan, D.C., Meier, U., Masci, J., Maria Gambardella, L., Schmidhuber, J.: Flexible, high performance convolutional neural networks for image classification. In: IJCAI Proceedings-International Joint Conference on Artificial Intelligence. vol. 22, p. 1237 (2011)\n\nIntroduction to Convolutional Neural Networks         11\n\n4. Cire\u015fan, D.C., Meier, U., Gambardella, L.M., Schmidhuber, J.: Convolutional neural network committees for handwritten character classification. In: Document Analysis and Recognition (ICDAR), 2011 International Conference on. pp. 1135\u20131139. IEEE (2011)\n\n5. Egmont-Petersen, M., de Ridder, D., Handels, H.: Image processing with neural networks a review. Pattern recognition 35(10), 2279\u20132301 (2002)\n\n6. Farabet, C., Martini, B., Akselrod, P., Talay, S., LeCun, Y., Culurciello, E.: Hardware accelerated convolutional neural networks for synthetic vision systems. In: Circuits and Systems (ISCAS), Proceedings of 2010 IEEE International Symposium on. pp. 257\u2013260. IEEE (2010)\n\n7. Hinton, G.: A practical guide to training restricted boltzmann machines. Momentum 9(1), 926 (2010)\n\n8. Hinton, G.E., Srivastava, N., Krizhevsky, A., Sutskever, I., Salakhutdinov, R.R.: Improving neural networks by preventing co-adaptation of feature detectors. arXiv preprint arXiv:1207.0580 (2012)\n\n9. Ji, S., Xu, W., Yang, M., Yu, K.: 3d convolutional neural networks for human action recognition. Pattern Analysis and Machine Intelligence, IEEE Transactions on 35(1), 221\u2013231 (2013)\n\n10. Karpathy, A., Toderici, G., Shetty, S., Leung, T., Sukthankar, R., Fei-Fei, L.: Large-scale video classification with convolutional neural networks. In: Computer Vision and Pattern Recognition (CVPR), 2014 IEEE Conference on. pp. 1725\u20131732. IEEE (2014)\n\n11. Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep convolutional neural networks. In: Advances in neural information processing systems. pp. 1097\u20131105 (2012)\n\n12. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.: Backpropagation applied to handwritten zip code recognition. Neural computation 1(4), 541\u2013551 (1989)\n\n13. LeCun, Y., Bottou, L., Bengio, Y., Haffner, P.: Gradient-based learning applied to document recognition. Proceedings of the IEEE 86(11), 2278\u20132324 (1998)\n\n14. Nebauer, C.: Evaluation of convolutional neural networks for visual recognition. Neural Networks, IEEE Transactions on 9(4), 685\u2013696 (1998)\n\n15. Simard, P.Y., Steinkraus, D., Platt, J.C.: Best practices for convolutional neural networks applied to visual document analysis. In: null. p. 958. IEEE (2003)\n\n16. Srivastava, N.: Improving neural networks with dropout. Ph.D. thesis, University of Toronto (2013)\n\n17. Szarvas, M., Yoshizawa, A., Yamamoto, M., Ogata, J.: Pedestrian detection with convolutional neural networks. In: Intelligent Vehicles Symposium, 2005. Proceedings. IEEE. pp. 224\u2013229. IEEE (2005)\n\n18. Szegedy, C., Toshev, A., Erhan, D.: Deep neural networks for object detection. In: Advances in Neural Information Processing Systems. pp. 2553\u20132561 (2013)\n\n19. Tivive, F.H.C., Bouzerdoum, A.: A new class of convolutional neural networks (siconnets) and their application of face detection. In: Neural Networks, 2003. Proceedings of the International Joint Conference on. vol. 3, pp. 2157\u20132162. IEEE (2003)\n\n20. Zeiler, M.D., Fergus, R.: Stochastic pooling for regularization of deep convolutional neural networks. arXiv preprint arXiv:1301.3557 (2013)\n\n21. Zeiler, M.D., Fergus, R.: Visualizing and understanding convolutional networks. In: Computer Vision\u2013ECCV 2014, pp. 818\u2013833. Springer (2014)",
                "similarity": 0.8521066904067993
            }
        ]
    }
}